{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä»é›¶æ‰‹æ“ä¸­æ–‡å¤§æ¨¡å‹ï½œğŸš€ Day07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFT æ•°æ®å‡†å¤‡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TinyStories`æ•°æ®é›†å…¶å®ä¹Ÿæä¾›äº†[Instructæ•°æ®](https://huggingface.co/datasets/roneneldan/TinyStoriesInstruct)ï¼Œæˆ‘å¯ä»¥åŸºäºè¿™ä¸ªæ•°æ®é›†åœ¨ä¹‹å‰çš„é¢„è®­ç»ƒæ¨¡å‹ä¸Šè¿›è¡ŒæŒ‡ä»¤å¾®è°ƒã€‚\n",
    "\n",
    "å…ˆçœ‹çœ‹æ•°æ®é›†çš„æ ¼å¼ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: Dialogue\n",
      "Words: quit, oak, gloomy\n",
      "Summary: Sara and Ben were playing in the park, but Sara wanted to go home because it was cold and dark. Ben convinced her to stay and play, but eventually agreed to go home and have hot cocoa.\n",
      "Story: \n",
      "\n",
      "Sara and Ben were playing in the park. They liked to climb the big oak tree and pretend they were birds. They made nests with leaves and twigs and sang songs.\n",
      "But today, the sky was gloomy and the wind was cold. Sara felt sad and cold. She wanted to go home and have some hot cocoa.\n",
      "\"Ben, I want to quit,\" she said. \"It's too cold and dark. Let's go home.\"\n",
      "Ben looked at Sara and frowned. He liked the oak tree and the park. He wanted to stay and play.\n",
      "\"No, Sara, don't quit,\" he said. \"It's fun here. Look, there's a squirrel. Let's chase it.\"\n"
     ]
    }
   ],
   "source": [
    "! head -10 ../../Data/TinyStoriesInstruct/TinyStories-Instruct-train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™äº›æŒ‡ä»¤æœ‰å››ç§ç±»å‹ï¼š\n",
    "1. ä¸€ä¸ªå•è¯åˆ—è¡¨ï¼ŒåŒ…å«åœ¨æ•…äº‹ä¸­ã€‚\n",
    "2. ä¸€ä¸ªå¥å­ï¼Œåº”è¯¥å‡ºç°åœ¨æ•…äº‹çš„æŸä¸ªåœ°æ–¹ã€‚\n",
    "3. ä¸€ä¸ªç‰¹å¾åˆ—è¡¨ï¼ˆå¯èƒ½çš„ç‰¹å¾ï¼šå¯¹è¯ã€åç»“å±€ã€é“å¾·ä»·å€¼ã€æƒ…èŠ‚è½¬æŠ˜ã€ä¼ç¬”ã€å†²çªï¼‰ã€‚\n",
    "4. ä¸€ä¸ªç®€çŸ­çš„æ€»ç»“ï¼ˆ1-2è¡Œï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨é¢ä¸´ä¸¤ä¸ªé—®é¢˜ï¼š\n",
    "- æ•°æ®é›†æ˜¯è‹±æ–‡çš„ï¼Œæˆ‘éœ€è¦æƒ³åŠæ³•ç»™æ•´æˆä¸­æ–‡çš„ã€‚\n",
    "- æ•°æ®é›†çš„å½¢å¼å’Œä¸»æµçš„SFTæ•°æ®é›†ä¸å¤ªä¸€æ ·ï¼Œéœ€è¦åšä¸€äº›é€‚é…ã€‚\n",
    "\n",
    "  > ä¸ªäººç†è§£è¿™é‡Œæ˜¯å› ä¸ºè¿™é‡Œçš„æŒ‡ä»¤ç›¸å¯¹å•ä¸€ï¼ˆç”Ÿæˆæ•…äº‹ï¼‰ï¼Œåªæ˜¯çº¦æŸæœ‰ä¸€äº›åŒºåˆ«ï¼Œæ‰€ä»¥ä½œè€…é‡‡å–äº†ç®€å•çš„æ‹¼æ¥æ–¹å¼ã€‚\n",
    "  >\n",
    "  > è¿™é‡Œå‡ºäºå­¦ä¹ çš„ç›®çš„è¿˜æ˜¯å¾€ä¸»æµçš„SFTæ•°æ®é›†ä¸Šé æ‹¢ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å´æ©è¾¾è€å¸ˆçš„ç¿»è¯‘Agentæµ‹è¯•\n",
    "\n",
    "è¿™é‡Œç›´æ¥è¯•äº†ä¸‹[å´æ©è¾¾è€å¸ˆçš„translation-agent](https://github.com/andrewyng/translation-agent)é¡¹ç›®ï¼ˆ`translation-agent.py`æ–‡ä»¶ï¼‰ï¼Œä½¿ç”¨çš„æ˜¯`gpt-4o-mini`çš„`api`ï¼ˆä¹Ÿå°è¯•è¿‡`Ollama`æœ¬åœ°éƒ¨ç½²çš„`qwen14b`ã€`qwen7b`ï¼Œç›¸å¯¹æ¥è¯´ä¸å¤ªç¨³å®šï¼‰ã€‚\n",
    "\n",
    "å¯ä»¥çœ‹åˆ°è¿™é‡Œå•æ¬¡ç¿»è¯‘çš„è€—æ—¶åœ¨10ç§’å·¦å³ï¼ˆå› ä¸ºå•è¯ç¿»è¯‘çš„æ—¶å€™`agent`é€»è¾‘é‡Œæœ‰å¤šæ¬¡`api`è°ƒç”¨ï¼‰ï¼Œå› æ­¤è¿™é‡Œä¸ºäº†åé¢èƒ½å¤Ÿå¹¶å‘è°ƒç”¨åˆ·æ•°æ®ï¼Œæˆ‘å°†ä»£ç å…¨éƒ¨æ”¹é€ æˆäº†`async`çš„å¼‚æ­¥è°ƒç”¨ã€‚\n",
    "\n",
    "å¤§å®¶å¦‚æœæœ‰å…¶ä»–çš„ç¿»è¯‘`api`æˆ–è€…æ¨¡å‹ä¹Ÿå¯ä»¥æ›¿æ¢ï¼Œè¿™é‡Œçº¯å±å¿ƒè¡€æ¥æ½®ç©ä¸€ç©å„¿ã€‚\n",
    "\n",
    "`translation-agent`é¡¹ç›®å…¶å®åªæœ‰ä¸€ä¸ª`utils.py`æ–‡ä»¶ï¼Œä½†å› ä¸ºå¤ªé•¿äº†ï¼Œè¿™é‡Œå°±ä¸æŠŠæ”¹é€ åçš„ä»£ç è´´å‡ºæ¥äº†ï¼Œæœ‰å…´è¶£çš„åŒå­¦å¯ä»¥å»ä»“åº“é‡ŒæŸ¥çœ‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| num_tokens_in_text: 416\n",
      "ic| 'Translating text as a single chunk'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "éšæœºå¥å­ï¼šä»–ä»¬éå¸¸å…´å¥‹ï¼Œä¹Ÿæƒ³é£ã€‚  \n",
      "ç‰¹ç‚¹ï¼šå¯¹è¯  \n",
      "æ‘˜è¦ï¼šæ±¤å§†å’Œå®‰å¨œå…´å¥‹åœ°å’Œçˆ¶æ¯ä¸€èµ·å»åº¦å‡ï¼Œä»–ä»¬ä¹˜åä¸€æ¶å¤§é£æœºé£å¾€é˜³å…‰æ˜åªšã€æ²™æ»©ç»†è…»çš„åœ°æ–¹ã€‚  \n",
      "æ•…äº‹ï¼š  \n",
      "æ±¤å§†å’Œå®‰å¨œæ˜¯å…„å¦¹ã€‚ä»–ä»¬å–œæ¬¢ç©ç©å…·å’Œè¯»ä¹¦ã€‚ä»–ä»¬éå¸¸å¼€å¿ƒï¼Œå› ä¸ºä»–ä»¬è¦å’Œçˆ¸çˆ¸å¦ˆå¦ˆä¸€èµ·å»åº¦å‡ã€‚ä»–ä»¬å°†ä¹˜åä¸€æ¶å¤§é£æœºå»ä¸€ä¸ªé˜³å…‰æ˜åªšã€æ²™æ»©ç»†è…»çš„åœ°æ–¹ã€‚  \n",
      "åº¦å‡çš„æ—¥å­åˆ°äº†ï¼Œä»–ä»¬å¼€å§‹æ•´ç†è¡Œæã€‚ä»–ä»¬å»æœºåœºï¼Œç­‰å¾…ä»–ä»¬çš„é£æœºã€‚ä»–ä»¬çœ‹åˆ°è®¸å¤šå…¶ä»–é£æœºåœ¨å¤©ç©ºä¸­é£ã€‚ä»–ä»¬éå¸¸å…´å¥‹ï¼Œä¹Ÿæƒ³é£ã€‚  \n",
      "â€œçœ‹ï¼Œå®‰å¨œï¼Œé‚£æ¶é£æœºåˆå¤§åˆå¿«ï¼â€æ±¤å§†è¯´ã€‚  \n",
      "â€œæ˜¯çš„ï¼Œæ±¤å§†ï¼Œå®ƒæœ‰ç¿…è†€å’Œå°¾å·´ã€‚æˆ‘æƒ³çŸ¥é“å®ƒè¦å»å“ªé‡Œï¼Œâ€å®‰å¨œè¯´ã€‚  \n",
      "ä»–ä»¬å¬åˆ°å¦ˆå¦ˆå«ä»–ä»¬ã€‚â€œå¿«ç‚¹ï¼Œå­©å­ä»¬ï¼Œå·®ä¸å¤šè¯¥ç™»æœºäº†ã€‚æˆ‘ä»¬å¿…é¡»å‡ºç¤ºæœºç¥¨ï¼Œç„¶åé€šè¿‡ç™»æœºå£ã€‚â€  \n",
      "ä»–ä»¬è·Ÿç€çˆ¸çˆ¸å¦ˆå¦ˆä¸Šäº†é£æœºã€‚ä»–ä»¬æ‰¾åˆ°è‡ªå·±çš„åº§ä½ï¼Œç³»å¥½å®‰å…¨å¸¦ã€‚ä»–ä»¬æœ›å‘çª—å¤–ï¼Œçœ‹åˆ°åœ°é¢ã€æ±½è½¦å’Œäººã€‚ä»–ä»¬å¬åˆ°é£è¡Œå‘˜åœ¨æ‰¬å£°å™¨ä¸Šè¯´è¯ã€‚  \n",
      "â€œå¤§å®¶å¥½ï¼Œæˆ‘æ˜¯ä½ ä»¬çš„æœºé•¿ã€‚æ¬¢è¿ä¹˜å123èˆªç­å‰å¾€é˜³å…‰æµ·æ»©ã€‚æˆ‘ä»¬å‡†å¤‡èµ·é£ã€‚è¯·åå¥½ï¼Œäº«å—æ—…ç¨‹ã€‚â€  \n",
      "é£æœºå¼€å§‹ç§»åŠ¨ï¼Œå‘å‡ºè½°é¸£çš„å£°éŸ³ã€‚æ±¤å§†å’Œå®‰å¨œæ„Ÿè§‰é£æœºè¶Šæ¥è¶Šå¿«ã€‚ä»–ä»¬çœ‹åˆ°åœ°é¢å˜å¾—è¶Šæ¥è¶Šå°ã€‚äº‘æœµè¶Šæ¥è¶Šè¿‘ã€‚ä»–ä»¬åœ¨é£ï¼  \n",
      "â€œå“‡ï¼Œå®‰å¨œï¼Œæˆ‘ä»¬åœ¨é£ï¼æˆ‘ä»¬åœ¨å¤©ç©ºä¸­ï¼â€æ±¤å§†è¯´ã€‚  \n",
      "â€œæˆ‘çŸ¥é“ï¼Œæ±¤å§†ï¼Œå¤ªç¥å¥‡äº†ï¼æˆ‘ä»¬è¿™ä¹ˆé«˜ï¼çœ‹ï¼Œé‚£é‡Œæ˜¯å¤ªé˜³ï¼â€å®‰å¨œè¯´ã€‚  \n",
      "ä»–ä»¬å¾®ç¬‘ã€æ¬¢ç¬‘ï¼Œæ‹æ‰‹æ¬¢å‘¼ã€‚ä»–ä»¬ä¸€ç‚¹éƒ½ä¸éš¾è¿‡ã€‚ä»–ä»¬éå¸¸å¿«ä¹ã€‚ä»–ä»¬æ­£åœ¨é£å¾€åº¦å‡çš„åœ°æ–¹ã€‚\n"
     ]
    }
   ],
   "source": [
    "from translation_agent import translate\n",
    "\n",
    "text = \"\"\"\n",
    "Random sentence: They are very excited and want to fly too.\n",
    "Features: Dialogue\n",
    "Summary: Tom and Anna are excited to go on a holiday with their parents, and they fly on a big plane to a place with sun and sand.\n",
    "Story: \n",
    "Tom and Anna are brother and sister. They like to play with their toys and read books. They are very happy because they are going on a holiday with their mum and dad. They will fly on a big plane to a place with a lot of sun and sand.\n",
    "The day of the holiday comes and they pack their bags. They go to the airport and wait for their plane. They see many other planes flying in the sky. They are very excited and want to fly too.\n",
    "\"Look, Anna, that plane is so big and fast!\" Tom says.\n",
    "\"Yes, Tom, and it has wings and a tail. I wonder where it is going,\" Anna says.\n",
    "They hear their mum call them. \"Come on, kids, it's time to board our plane. We have to show our tickets and go through the gate.\"\n",
    "They follow their mum and dad and get on their plane. They find their seats and buckle their belts. They look out the window and see the ground and the cars and the people. They hear the pilot say something on the speaker.\n",
    "\"Hello, everyone, this is your pilot speaking. Welcome aboard flight 123 to Sunny Beach. We are ready to take off. Please sit back and enjoy the flight.\"\n",
    "The plane starts to move and makes a loud noise. Tom and Anna feel the plane go faster and faster. They see the ground get smaller and smaller. They see the clouds get closer and closer. They are flying!\n",
    "\"Wow, Anna, we are flying! We are in the sky!\" Tom says.\n",
    "\"I know, Tom, it's amazing! We are so high! Look, there is the sun!\" Anna says.\n",
    "They smile and laugh and clap their hands. They are not sad at all. They are very happy. They are flying to their holiday.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "result = await translate(\n",
    "    source_lang=\"English\",\n",
    "    target_lang=\"Chinese\",\n",
    "    source_text=text,\n",
    "    country=\"China\",\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ•°æ®é‡‡æ ·\n",
    "\n",
    "æˆ‘å…ˆçœ‹çœ‹è®­ç»ƒé›†æœ‰å¤šå°‘æ¡æ•°æ®ï¼Œå¯ä»¥å‘ç°æ–‡æœ¬éƒ½æ˜¯ä»¥`<|endoftext|>`ç»“å°¾çš„ï¼Œæ‰€ä»¥é€šè¿‡ç»Ÿè®¡`endoftext`çš„ä¸ªæ•°å°±å¯ä»¥çŸ¥é“æ•°æ®é›†çš„æ¡æ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2476532\n"
     ]
    }
   ],
   "source": [
    "! grep -o \"endoftext\" ../../Data/TinyStoriesInstruct/TinyStories-Instruct-train.txt  | wc -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¥è¿‘250wçš„é‡çº§æœ‰ç‚¹å¤§ï¼ˆå› ä¸ºå¾®è½¯çš„è®ºæ–‡é‡Œæ˜¯ç›´æ¥åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šåšçš„`pretrain`çš„ï¼‰ã€‚\n",
    "\n",
    "å…¶å®å¾ˆå¤šç ”ç©¶è¡¨æ˜ï¼Œ`SFT`æ•°æ®çš„é‡çº§ä¸é‡è¦ï¼Œè´¨é‡å¤Ÿé«˜çš„æ—¶å€™å³ä½¿å¾ˆå°‘çš„æ•°æ®ä¹Ÿèƒ½è®­ç»ƒå‡ºå¾ˆå¥½çš„æ•ˆæœã€‚\n",
    "\n",
    "æ‰€ä»¥è¿™é‡Œæˆ‘æ‰“ç®—éšæœºæŠ½å–11000æ¡æ•°æ®æ¥è¯•è¯•ã€‚\n",
    "\n",
    "æˆ‘çš„ç­–ç•¥å¦‚ä¸‹ï¼š\n",
    "1. éå†`train`æ•°æ®é›†ï¼Œè®©å››ç±»æŒ‡ä»¤çš„ç»„åˆå°½é‡å‡è¡¡ï¼ˆéœ€è¦å…ˆç»Ÿè®¡æŒ‡ä»¤ç»„åˆçš„çš„åˆ†å¸ƒï¼‰\n",
    "2. ç”¨å¾—åˆ°çš„11000æ¡æ•°æ®è°ƒç”¨ä¸Šé¢çš„`translation-agent`è¿›è¡Œç¿»è¯‘\n",
    "3. å°†ç¿»è¯‘åçš„æ•°æ®æ•´ç†æˆ`SFT`æ•°æ®é›†çš„`json`æ ¼å¼\n",
    "\n",
    "å…ˆæ¥åšæ•°æ®çš„é‡‡æ ·ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "\n",
    "def count_field_combinations(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    blocks = content.split(\"<|endoftext|>\")\n",
    "    combinations = []\n",
    "\n",
    "    for block in blocks:\n",
    "        fields = set()\n",
    "        if \"Words:\" in block:\n",
    "            fields.add(\"Words\")\n",
    "        if \"Random sentence:\" in block:\n",
    "            fields.add(\"Random sentence\")\n",
    "        if \"Features:\" in block:\n",
    "            fields.add(\"Features\")\n",
    "        if \"Summary:\" in block:\n",
    "            fields.add(\"Summary\")\n",
    "\n",
    "        if fields:  # åªæœ‰å½“å­—æ®µä¸ä¸ºç©ºæ—¶æ‰æ·»åŠ ç»„åˆ\n",
    "            combinations.append(frozenset(fields))\n",
    "\n",
    "    return Counter(combinations)\n",
    "\n",
    "\n",
    "def sample_data(file_path, total_samples=11000):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    blocks = content.split(\"<|endoftext|>\")\n",
    "    blocks = [block.strip() for block in blocks if block.strip()]  # ç§»é™¤ç©ºå—\n",
    "\n",
    "    combinations = count_field_combinations(file_path)\n",
    "    combination_more_than_1 = {k: v for k, v in combinations.items() if v > 1}\n",
    "    samples_per_combination = total_samples // len(combination_more_than_1)\n",
    "\n",
    "    sampled_data = []\n",
    "    for combination in combinations:\n",
    "        matching_blocks = [\n",
    "            block for block in blocks if set(get_fields(block)) == set(combination)\n",
    "        ]\n",
    "        sampled_data.extend(\n",
    "            random.sample(\n",
    "                matching_blocks, min(samples_per_combination, len(matching_blocks))\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return sampled_data\n",
    "\n",
    "\n",
    "def get_fields(block):\n",
    "    fields = set()\n",
    "    if \"Words:\" in block:\n",
    "        fields.add(\"Words\")\n",
    "    if \"Random sentence:\" in block:\n",
    "        fields.add(\"Random sentence\")\n",
    "    if \"Features:\" in block:\n",
    "        fields.add(\"Features\")\n",
    "    if \"Summary:\" in block:\n",
    "        fields.add(\"Summary\")\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ‰§è¡Œä¸€ä¸‹çœ‹çœ‹æ•ˆæœï¼ˆä¸ºäº†æœ‰å¤‡æ— æ‚£ï¼Œå¤šé‡‡æ ·äº†5000æ¡æ•°æ®ï¼‰ï¼Œè€—æ—¶1-2åˆ†é’Ÿï¼Œè‚¯å®šè¿˜æœ‰ä¼˜åŒ–ç©ºé—´ï¼Œä½†æ˜¯å¯ä»¥æ¥å—ã€‚\n",
    "\n",
    "åŒæ—¶å°†é‡‡æ ·åçš„æ•°æ®ä¿å­˜ä¸º`pkl`æ–‡ä»¶ï¼Œæ–¹ä¾¿åç»­ä½¿ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é‡‡æ ·æ•°æ®æ€»æ•°: 15001\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# sft_raw = sample_data(\n",
    "#     \"../../Data/TinyStoriesInstruct/TinyStories-Instruct-train.txt\", 15000\n",
    "# )\n",
    "sft_raw = pickle.load(open(\"sft_raw.pkl\", \"rb\"))\n",
    "print(f\"é‡‡æ ·æ•°æ®æ€»æ•°: {len(sft_raw)}\")\n",
    "\n",
    "# pickle.dump(sft_raw, open(\"sft_raw.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ‰¹é‡ç¿»è¯‘\n",
    "\n",
    "æ¥ä¸‹æ¥å°±å¯ä»¥è°ƒç”¨`translation-agent`è¿›è¡Œç¿»è¯‘äº†ã€‚\n",
    "\n",
    "è¿™é‡Œæˆ‘é™¤äº†ç”¨å¼‚æ­¥åŠ é€Ÿï¼Œè¿˜ä½¿ç”¨äº†`json`æ–‡ä»¶ç¼“å­˜æ¥é¿å…é‡å¤ç¿»è¯‘ï¼ˆ`gpt-4o-mini`çš„`api`ä¹Ÿä¸ç®—ä¾¿å®œï¼Œèƒ½çœåˆ™çœï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import aiofiles\n",
    "import asyncio\n",
    "\n",
    "cache_file = \"translation_cache.json\"\n",
    "\n",
    "\n",
    "async def translate_and_cache(block, cache, semaphore):\n",
    "    cache_key = hash(block)\n",
    "\n",
    "    if str(cache_key) in cache:\n",
    "        return cache[str(cache_key)]\n",
    "\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            result = await translate(\n",
    "                source_lang=\"English\",\n",
    "                target_lang=\"Chinese\",\n",
    "                source_text=block,\n",
    "                country=\"China\",\n",
    "            )\n",
    "            cache[str(cache_key)] = result\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"ç¿»è¯‘å¤±è´¥: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "async def batch_translate(sampled_data, cache_file, max_workers=10):\n",
    "    translated_data = []\n",
    "\n",
    "    try:\n",
    "        async with aiofiles.open(cache_file, \"r\") as f:\n",
    "            cache = json.loads(await f.read())\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        cache = {}\n",
    "\n",
    "    semaphore = asyncio.Semaphore(max_workers)\n",
    "    tasks = [translate_and_cache(block, cache, semaphore) for block in sampled_data]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    translated_data = [result for result in results if result]\n",
    "\n",
    "    async with aiofiles.open(cache_file, \"w\") as f:\n",
    "        await f.write(json.dumps(cache, ensure_ascii=False, indent=2))\n",
    "\n",
    "    return translated_data\n",
    "\n",
    "\n",
    "translated_data = await batch_translate(sft_raw, cache_file, max_workers=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨äº†100è·¯çš„å¹¶å‘ï¼Œç¿»è¯‘äº†15000æ¡æ•°æ®ï¼Œè€—æ—¶48åˆ†é’Ÿï¼Œä¹Ÿå°±æ˜¯å¤§æ¦‚æ¯åˆ†é’Ÿç¿»è¯‘300æ¡æ•°æ®ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åç»­å¤„ç†\n",
    "\n",
    "ç¿»è¯‘å®Œæˆäº†ï¼Œæœ€åä¸€æ­¥å°±æ˜¯å°†æ•°æ®æ•´ç†æˆ`SFT`æ•°æ®é›†çš„æ ¼å¼ã€‚\n",
    "\n",
    "ï¼ˆè¿™é‡Œè¿˜å‘ç°äº†ä¸ªå°é—®é¢˜ï¼Œç¿»è¯‘ç»Ÿä¸€å°†**æ€»ç»“**å­—æ®µæ”¾åˆ°äº†æœ€åï¼Œå¯¼è‡´é¡ºåºå‡ºç°äº†é—®é¢˜ï¼Œæ‰€ä»¥è¿™é‡Œéœ€è¦å…ˆå¤„ç†ä¸€ä¸‹ã€‚ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import random\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "instruction_template = \"æŒ‰ç…§ä¸‹é¢è¾“å…¥çš„çº¦æŸç”Ÿæˆæ•…äº‹\"\n",
    "\n",
    "\n",
    "def process_translated_data(input_file):\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    processed_data = []\n",
    "    constraint_keys = Counter()\n",
    "\n",
    "    for key, value in data.items():\n",
    "        if \"æ•…äº‹ï¼š\" not in value:\n",
    "            continue\n",
    "        parts = value.split(\"æ•…äº‹ï¼š\")\n",
    "\n",
    "        if len(parts) == 2:\n",
    "            input_text = parts[0].strip()\n",
    "            output_text = parts[1].strip()\n",
    "\n",
    "            # æå–çº¦æŸæè¿°æ–‡æœ¬çš„å…³é”®å­—æ®µ\n",
    "            lines = input_text.split(\"\\n\")\n",
    "            for line in lines:\n",
    "                if \"ï¼š\" in line:\n",
    "                    key, _ = line.split(\"ï¼š\", 1)\n",
    "                    constraint_keys[key.strip()] += 1\n",
    "\n",
    "            processed_item = {\n",
    "                \"instruction\": instruction_template,\n",
    "                \"input\": f\"{input_text}\",\n",
    "                \"output\": output_text,\n",
    "            }\n",
    "\n",
    "            processed_data.append(processed_item)\n",
    "    # æ ¹æ®constraint_keysçš„é¢‘ç‡æ’åºï¼Œé€‰å–å‡ºç°é¢‘ç‡å¤§äº10çš„å…³é”®å­—\n",
    "    constraint_keys = {k: v for k, v in constraint_keys.items() if v > 10}\n",
    "    return constraint_keys, processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_keys, processed_data = process_translated_data(\"translation_cache.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_normalization = {\n",
    "    \"è¯æ±‡\": \"è¯æ±‡\",\n",
    "    \"å…³é”®è¯\": \"è¯æ±‡\",\n",
    "    \"å•è¯\": \"è¯æ±‡\",\n",
    "    \"è¯è¯­\": \"è¯æ±‡\",\n",
    "    \"è¯\": \"è¯æ±‡\",\n",
    "    \"å­—\": \"è¯æ±‡\",\n",
    "    \"ç‰¹å¾\": \"ç‰¹å¾\",\n",
    "    \"ç‰¹ç‚¹\": \"ç‰¹å¾\",\n",
    "    \"æ•…äº‹ç‰¹ç‚¹\": \"ç‰¹å¾\",\n",
    "    \"æ•…äº‹ç‰¹å¾\": \"ç‰¹å¾\",\n",
    "    \"å¯¹è¯ç‰¹ç‚¹\": \"ç‰¹å¾\",\n",
    "    \"ä¸»é¢˜\": \"ç‰¹å¾\",\n",
    "    \"éšæœºå¥å­\": \"éšæœºå¥å­\",\n",
    "    \"éšä¾¿ä¸€å¥è¯\": \"éšæœºå¥å­\",\n",
    "    \"éšæœºä¸€å¥è¯\": \"éšæœºå¥å­\",\n",
    "    \"éšæœºå¥\": \"éšæœºå¥å­\",\n",
    "    \"éšæœºçš„ä¸€å¥è¯\": \"éšæœºå¥å­\",\n",
    "    \"éšæœºçš„å¥å­\": \"éšæœºå¥å­\",\n",
    "    \"éšæœºå¥å­æ˜¯\": \"éšæœºå¥å­\",\n",
    "    \"éšä¾¿è¯´ä¸€å¥\": \"éšæœºå¥å­\",\n",
    "    \"éšä¾¿ä¸€å¥\": \"éšæœºå¥å­\",\n",
    "    \"éšæœºå¥å­ç¤ºä¾‹\": \"éšæœºå¥å­\",\n",
    "    \"æ‘˜è¦\": \"æ‘˜è¦\",\n",
    "    \"æ€»ç»“\": \"æ‘˜è¦\",\n",
    "    \"æ•…äº‹æ¦‚è¦\": \"æ‘˜è¦\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, keys):\n",
    "    result = []\n",
    "    current_key = None\n",
    "    current_content = \"\"\n",
    "\n",
    "    for line in data.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        if any(key in line for key in keys):\n",
    "            if current_key:\n",
    "                result.append((current_key, current_content.strip()))\n",
    "            for key in keys:\n",
    "                if key in line:\n",
    "                    current_key, current_content = line.split(key, 1)\n",
    "                    current_key = key.strip()\n",
    "                    current_content = current_content.strip().lstrip(\"ï¼š\").strip()\n",
    "                    break\n",
    "        else:\n",
    "            current_content += \" \" + line\n",
    "\n",
    "    if current_key:\n",
    "        result.append((current_key, current_content.strip()))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def filter_and_normalize(\n",
    "    processed_data, constraint_keys, output_file, expand_data=True\n",
    "):\n",
    "    final_data = []\n",
    "    for item in processed_data:\n",
    "        input_text = item[\"input\"]\n",
    "        output_text = item[\"output\"]\n",
    "        has_keyword = False\n",
    "        for keyword in keywords_normalization:\n",
    "            if f\"{keyword}ï¼š\" in output_text:\n",
    "                content = output_text.split(f\"{keyword}ï¼š\")[1].strip()\n",
    "                input_text += f\"\\n{keyword}ï¼š{content}\"\n",
    "                output_text = output_text.split(f\"{keyword}ï¼š\")[0].strip()\n",
    "                has_keyword = True\n",
    "            if f\"{keyword}ï¼š\" in input_text:\n",
    "                input_text = input_text.replace(\n",
    "                    f\"{keyword}ï¼š\", f\"{keywords_normalization[keyword]}ï¼š\"\n",
    "                )\n",
    "                has_keyword = True\n",
    "        if not has_keyword:\n",
    "            continue\n",
    "\n",
    "        # æ•°æ®å¢å¼º\n",
    "        if expand_data:\n",
    "            input_tuple_list = split_data(input_text, keywords_normalization)\n",
    "            if not input_tuple_list:\n",
    "                continue\n",
    "\n",
    "            for permutation in itertools.permutations(input_tuple_list):\n",
    "                new_item = {\n",
    "                    \"instruction\": instruction_template,\n",
    "                    \"input\": \"\\n\".join(\n",
    "                        [f\"{key}ï¼š{value}\" for key, value in permutation]\n",
    "                    ),\n",
    "                    \"output\": output_text,\n",
    "                }\n",
    "                final_data.append(new_item)\n",
    "        else:\n",
    "            item.update({\"input\": input_text, \"output\": output_text})\n",
    "            final_data.append(item)\n",
    "\n",
    "    # å¯¹ç»“æœåšä¸€ä¸ªæ‰“ä¹±\n",
    "    random.shuffle(final_data)\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(final_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = filter_and_normalize(\n",
    "    processed_data,\n",
    "    keywords_normalization,\n",
    "    \"../../Data/TinyStoriesInstruct/sft_data_v2.json\",\n",
    "    True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "çœ‹ä¸€çœ‹å¤„ç†çš„ç»“æœï¼Œè¿™æ ·å°±å’Œç»å…¸çš„`SFT`æ•°æ®æ ¼å¼ä¸€è‡´äº†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'éšæœºå¥å­ï¼šéšæœºå¥å­ï¼šè’‚å§†çš„ç½‘çƒæ°´å¹³è¶Šæ¥è¶Šå¥½ï¼Œä½†æœ‰æ—¶ä»–åœ¨é”™è¿‡çƒçš„æ—¶å€™ä¼šæ„Ÿåˆ°ä¸è€çƒ¦ã€‚\\n'\n",
      "          'ç‰¹å¾ï¼šå¯¹è¯\\n'\n",
      "          'æ‘˜è¦ï¼šè’‚å§†å’Œä»–çš„çˆ¸çˆ¸ä¸€èµ·æ‰“ç½‘çƒï¼Œä½†å½“è’‚å§†é”™è¿‡çƒæ—¶ä¼šæ„Ÿåˆ°ä¸è€çƒ¦ã€‚ä»–çš„çˆ¸çˆ¸é¼“åŠ±ä»–åšæŒç»ƒä¹ ï¼Œæœ€ç»ˆè’‚å§†æˆåŠŸæŠŠçƒæ‰“è¿‡äº†ç½‘ï¼Œå¹¶ä¸ºè‡ªå·±æ„Ÿåˆ°éª„å‚²ã€‚',\n",
      " 'instruction': 'æŒ‰ç…§ä¸‹é¢è¾“å…¥çš„çº¦æŸç”Ÿæˆæ•…äº‹',\n",
      " 'output': 'ä»å‰ï¼Œæœ‰ä¸ªå«è’‚å§†çš„å°ç”·å­©ã€‚è’‚å§†å–œæ¬¢å’Œä»–çš„çˆ¸çˆ¸æ‰“ç½‘çƒã€‚ä»–ä»¬ä¼šå»å…¬å›­ï¼Œæ¥å›å‡»çƒã€‚è’‚å§†çš„ç½‘çƒæ°´å¹³è¶Šæ¥è¶Šå¥½ï¼Œä½†æœ‰æ—¶ä»–åœ¨é”™è¿‡çƒçš„æ—¶å€™ä¼šæ„Ÿåˆ°ä¸è€çƒ¦ã€‚  \\n'\n",
      "           'ä¸€å¤©ï¼Œè’‚å§†å’Œä»–çš„çˆ¸çˆ¸åœ¨æ‰“ç½‘çƒï¼Œè’‚å§†é”™è¿‡äº†å¾ˆå¤šæ¬¡çƒã€‚ä»–å˜å¾—å¾ˆä¸è€çƒ¦ï¼Œç”šè‡³å“­äº†èµ·æ¥ã€‚ä»–çš„çˆ¸çˆ¸è¯´ï¼šâ€œåˆ«æ‹…å¿ƒï¼Œè’‚å§†ã€‚ä½ é€šè¿‡ç»ƒä¹ ä¼šå˜å¾—æ›´å¥½çš„ã€‚â€  \\n'\n",
      "           'çˆ¸çˆ¸ç»™è’‚å§†å‘äº†ä¸ªçƒï¼Œè’‚å§†æŠŠçƒæ‰“è¿‡äº†ç½‘ã€‚ä»–é«˜å…´å¾—ä¸å¾—äº†ï¼è’‚å§†è¯´ï¼šâ€œæˆ‘æˆåŠŸäº†ï¼Œçˆ¸çˆ¸ï¼â€  \\n'\n",
      "           'ä»–çš„çˆ¸çˆ¸å¾®ç¬‘ç€è¯´ï¼šâ€œæ²¡é”™ï¼Œä½ æˆåŠŸäº†ï¼ç°åœ¨æˆ‘ä»¬ç»§ç»­ç©ï¼Œäº«å—å…¶ä¸­çš„ä¹è¶£ã€‚â€è’‚å§†æ„Ÿåˆ°éå¸¸è‡ªè±ªï¼Œä¸€ç›´æ‰“çƒï¼Œç›´åˆ°è¯¥å›å®¶çš„æ—¶å€™ã€‚'}\n",
      "{'input': 'è¯æ±‡ï¼šæ’’è°ï¼Œæ‰“æ¶ï¼Œå¤§\\n'\n",
      "          'æ‘˜è¦ï¼šè‰¾è‰è¿™åªå¤§è±¡å¸®åŠ©æœ‹å‹ä»¬è’‚ç±³å’Œè¨ç±³å’Œè§£ï¼Œå¼ºè°ƒäº†å‹è°Šå’Œä¸€èµ·ç©çš„é‡è¦æ€§ã€‚\\n'\n",
      "          'éšæœºå¥å­ï¼šè‰¾è‰å’Œå¥¹çš„æœ‹å‹ä»¬ä½åœ¨ä¸€ç‰‡å¤§ä¸›æ—é‡Œã€‚\\n'\n",
      "          'ç‰¹å¾ï¼šå¯¹è¯',\n",
      " 'instruction': 'æŒ‰ç…§ä¸‹é¢è¾“å…¥çš„çº¦æŸç”Ÿæˆæ•…äº‹',\n",
      " 'output': 'ä»å‰ï¼Œæœ‰ä¸€åªå«è‰¾è‰çš„å¤§è±¡ã€‚è‰¾è‰å’Œå¥¹çš„æœ‹å‹ä»¬ä½åœ¨ä¸€ç‰‡å¤§ä¸›æ—é‡Œã€‚ä¸€å¤©ï¼Œè‰¾è‰çœ‹åˆ°å¥¹çš„æœ‹å‹è€è™è’‚ç±³èººåœ¨åœ°ä¸Šã€‚  \\n'\n",
      "           'è‰¾è‰é—®ï¼šâ€œè’‚ç±³ï¼Œä½ æ€ä¹ˆèººç€ï¼Ÿâ€  \\n'\n",
      "           'â€œæˆ‘å’Œè›‡è¨ç±³æ‰“æ¶ï¼Œâ€è’‚ç±³æ‚²ä¼¤åœ°å›ç­”ã€‚  \\n'\n",
      "           'è‰¾è‰çœ‹åˆ°æœ‹å‹ä»¬æ‰“æ¶ï¼Œå¿ƒé‡Œå¾ˆéš¾è¿‡ã€‚å¥¹è¯´ï¼šâ€œæ‰“æ¶å¯ä¸å¥½ï¼Œæˆ‘ä»¬åº”è¯¥åšæœ‹å‹ï¼Œä¸€èµ·ç©ã€‚â€  \\n'\n",
      "           'è’‚ç±³åŒæ„äº†è‰¾è‰ï¼Œä»–ä»¬ä¸€èµ·å»æ‰¾è¨ç±³ã€‚å½“ä»–ä»¬æ‰¾åˆ°è¨ç±³æ—¶ï¼Œä»–ä»¬äº’ç›¸é“æ­‰ï¼Œé‡æ–°æˆä¸ºäº†å¥½æœ‹å‹ã€‚ä»é‚£å¤©èµ·ï¼Œä»–ä»¬éƒ½ä¸€èµ·ç©ï¼Œåœ¨ä¸›æ—é‡Œç©å¾—å¾ˆå¼€å¿ƒã€‚'}\n",
      "{'input': 'è¯æ±‡ï¼šæ»šï¼Œæ¯”è¨ï¼Œæ‰“å¼€\\n'\n",
      "          'æ‘˜è¦ï¼šè’‚å§†è¯•å›¾ä»ä¸€å®¶å¼€ç€çš„æ¯”è¨åº—æ‹¿ä¸€å—å¤§æ¯”è¨ï¼Œä½†å®ƒå¤ªå¤§äº†ï¼Œæ‰€ä»¥ä»–å†³å®šæŠŠå®ƒæ»šèµ°ã€‚ä¸€åªç‹—çœ‹åˆ°äº†æ¯”è¨ï¼Œè¿½ç€è’‚å§†ï¼Œåƒæ‰äº†æ¯”è¨ï¼Œç•™ä¸‹è’‚å§†æ„Ÿåˆ°ä¼¤å¿ƒã€‚',\n",
      " 'instruction': 'æŒ‰ç…§ä¸‹é¢è¾“å…¥çš„çº¦æŸç”Ÿæˆæ•…äº‹',\n",
      " 'output': 'ä¸€å¤©ï¼Œä¸€ä¸ªåå«è’‚å§†çš„ç”·å­©å»äº†æ¯”è¨åº—ã€‚ä»–ç‰¹åˆ«å–œæ¬¢æ¯”è¨ã€‚åœ¨æ¯”è¨åº—é‡Œï¼Œä»–çœ‹åˆ°æ¡Œå­ä¸Šæœ‰ä¸€ä¸ªå¤§æ¯”è¨ã€‚å®ƒçœ‹èµ·æ¥å¾ˆå¥½åƒï¼  \\n'\n",
      "           'è’‚å§†è¯´ï¼šâ€œå“‡ï¼Œæˆ‘æƒ³åƒé‚£å—æ¯”è¨ï¼â€ä»–è¯•å›¾æ‹¿èµ·æ¯”è¨ï¼Œä½†å®ƒå¤ªå¤§äº†ã€‚æ‰€ä»¥ï¼Œä»–å†³å®šæŠŠæ¯”è¨æ»šèµ°ã€‚ä»–æŠŠæ¯”è¨æ»šå‡ºäº†æ¯”è¨åº—ã€‚  \\n'\n",
      "           'å½“è’‚å§†æŠŠæ¯”è¨æ»šä¸‹è¡—çš„æ—¶å€™ï¼Œä¸€åªå¤§ç‹—çœ‹åˆ°äº†æ¯”è¨ã€‚é‚£åªç‹—å¾ˆé¥¿ã€‚ç‹—è¯´ï¼šâ€œæˆ‘ä¹Ÿæƒ³åƒé‚£å—æ¯”è¨ï¼â€ç‹—å¼€å§‹è¿½ç€è’‚å§†å’Œä»–çš„æ¯”è¨ã€‚  \\n'\n",
      "           'è’‚å§†è·‘å¾—å¾ˆå¿«ï¼Œä½†ç‹—è·‘å¾—æ›´å¿«ã€‚ç‹—è¿½ä¸Šäº†è’‚å§†å’Œä»–çš„æ¯”è¨ã€‚ç‹—åƒæ‰äº†æ•´å—æ¯”è¨ï¼Œè’‚å§†æ„Ÿåˆ°ä¼¤å¿ƒã€‚é‚£å¤©ä»–ä¸€å£æ¯”è¨éƒ½æ²¡åƒåˆ°ã€‚'}\n",
      "{'input': 'è¯æ±‡ï¼šé¼“æŒï¼Œæµ·æ´‹ï¼Œå±é™©\\n'\n",
      "          'ç‰¹å¾ï¼šå¯¹è¯\\n'\n",
      "          'æ‘˜è¦ï¼šè‰è‰å’Œè¨å§†æƒ³åœ¨æµ·æ´‹ä¸­æ¸¸æ³³ï¼Œä½†ä»–ä»¬çš„çˆ¶æ¯è¯´å¤ªå±é™©äº†ã€‚ä»–ä»¬åœ¨å²¸è¾¹å’Œæ–°æœ‹å‹ä¸€èµ·ç©çƒå’Œæ”¾é£ç­ï¼Œç©å¾—å¾ˆå¼€å¿ƒã€‚ä»–ä»¬åœ¨æ°´ä¸­çœ‹åˆ°ä¸€åªæµ·è±šï¼Œäº†è§£åˆ°æµ·æ´‹æ—¢ç¾å¦™åˆå±é™©ã€‚',\n",
      " 'instruction': 'æŒ‰ç…§ä¸‹é¢è¾“å…¥çš„çº¦æŸç”Ÿæˆæ•…äº‹',\n",
      " 'output': 'è‰è‰å’Œè¨å§†å’Œä»–ä»¬çš„çˆ¸çˆ¸å¦ˆå¦ˆåœ¨æµ·æ»©ä¸Šã€‚ä»–ä»¬å–œæ¬¢åœ¨æ²™å­é‡Œç©è€ï¼Œæ¬£èµæµ·æ´‹ã€‚æµ·æ´‹åˆå¤§åˆè“ï¼Œå‘å‡ºéš†éš†çš„å£°éŸ³ã€‚  \\n'\n",
      "           'â€œå¦ˆå¦ˆï¼Œæˆ‘ä»¬å¯ä»¥ä¸‹æ°´å—ï¼Ÿâ€è‰è‰é—®ã€‚  \\n'\n",
      "           'â€œä¸è¡Œï¼Œäº²çˆ±çš„ï¼Œä»Šå¤©æ°´å¤ªå±é™©äº†ã€‚æœ‰å¤§æµªå’Œå¼ºæµã€‚ä½ ä»¬å¯èƒ½ä¼šå—ä¼¤æˆ–è€…è¿·è·¯ï¼Œâ€å¦ˆå¦ˆè¯´ã€‚  \\n'\n",
      "           'â€œä½†æ˜¯æˆ‘æƒ³æ¸¸æ³³ï¼Œå¦ˆå¦ˆã€‚æˆ‘æ¸¸å¾—å¾ˆå¥½ã€‚ä½ æ•™è¿‡æˆ‘æ€ä¹ˆæ¸¸æ³³ï¼Œè®°å¾—å—ï¼Ÿâ€è¨å§†è¯´ã€‚  \\n'\n",
      "           'â€œæˆ‘çŸ¥é“ï¼Œäº²çˆ±çš„ï¼Œä½†åœ¨æµ·æ´‹é‡Œæ¸¸æ³³å’Œåœ¨æ¸¸æ³³æ± é‡Œæ¸¸æ³³æ˜¯ä¸åŒçš„ã€‚æµ·æ´‹å¯¹ä½ ä»¬è¿™ç§å°å­©æ¥è¯´ä¸å®‰å…¨ã€‚ä½ ä»¬å¿…é¡»å¬çˆ¸çˆ¸å¦ˆå¦ˆçš„è¯ï¼Œå¾…åœ¨å²¸è¾¹ï¼Œå¥½å—ï¼Ÿâ€çˆ¸çˆ¸è¯´ã€‚  \\n'\n",
      "           'è‰è‰å’Œè¨å§†æ„Ÿåˆ°éš¾è¿‡ã€‚ä»–ä»¬æƒ³åœ¨æ°´é‡Œç©å¾—å¼€å¿ƒã€‚ä»–ä»¬çœ‹åˆ°å…¶ä»–å°æœ‹å‹åœ¨ç©çƒå’Œæ”¾é£ç­ã€‚ä»–ä»¬å†³å®šåŠ å…¥ä»–ä»¬ï¼Œäº¤ä¸€äº›æ–°æœ‹å‹ã€‚  \\n'\n",
      "           'ä»–ä»¬ç©çƒå’Œæ”¾é£ç­ç©å¾—ç‰¹åˆ«å¼€å¿ƒã€‚ä»–ä»¬äº’ç›¸æ‰”çƒï¼Œè¿½ç€é£ç­è·‘ã€‚ä»–ä»¬æ¬¢ç¬‘ã€å–Šå«ã€æ¬¢å‘¼ã€‚ä»–ä»¬å¿˜è®°äº†æ°´ï¼Œäº«å—ç€é˜³å…‰å’Œå¾®é£ã€‚  \\n'\n",
      "           'ä¸ä¹…ï¼Œåˆ°äº†å›å®¶çš„æ—¶é—´ã€‚çˆ¸çˆ¸å¦ˆå¦ˆæ”¶æ‹¾å¥½ä¸œè¥¿ï¼Œå«è‰è‰å’Œè¨å§†ã€‚ä»–ä»¬å’Œæ–°æœ‹å‹é“åˆ«ï¼Œæ„Ÿè°¢ä»–ä»¬ä¸€èµ·ç©ã€‚  \\n'\n",
      "           'å½“ä»–ä»¬èµ°å‘è½¦æ—¶ï¼Œä»–ä»¬çœ‹åˆ°ç å¤´ä¸Šæœ‰ä¸€ç¾¤äººã€‚ä»–ä»¬åœ¨çœ‹æ°´é‡Œçš„ä¸œè¥¿ã€‚ä»–ä»¬å¬åˆ°äº†ä¸€äº›é¼“æŒå’Œæ¬¢å‘¼å£°ã€‚  \\n'\n",
      "           'â€œä»–ä»¬åœ¨çœ‹ä»€ä¹ˆï¼Œçˆ¸çˆ¸ï¼Ÿâ€è‰è‰é—®ã€‚  \\n'\n",
      "           'â€œæˆ‘ä»¬å»çœ‹çœ‹ï¼Œäº²çˆ±çš„ï¼Œâ€çˆ¸çˆ¸è¯´ã€‚  \\n'\n",
      "           'ä»–ä»¬èµ°åˆ°ç å¤´ï¼Œçœ‹åˆ°ä¸€æ¡å¤§é±¼ä»æ°´é‡Œè·³å‡ºæ¥ã€‚å®ƒæ˜¯ç°è‰²çš„ï¼Œé—ªé—ªå‘äº®ï¼Œé¼»å­è¿˜å¾ˆé•¿ã€‚å®ƒæ˜¯ä¸€åªæµ·è±šã€‚å®ƒåœ¨æ³¢æµªä¸­ç©è€å’Œè·³èˆã€‚å®ƒå‘å‡ºä¸€äº›æœ‰è¶£çš„å£°éŸ³ï¼Œæº…èµ·æ°´èŠ±ã€‚  \\n'\n",
      "           'â€œå“‡ï¼Œçœ‹çœ‹é‚£ä¸ªï¼Œè¨å§†ã€‚æ˜¯ä¸€åªæµ·è±šã€‚å¤ªé…·äº†ï¼Œâ€è‰è‰è¯´ã€‚  \\n'\n",
      "           'â€œå¤ªç¥å¥‡äº†ï¼Œè‰è‰ã€‚å®ƒèªæ˜åˆå‹å¥½ã€‚å®ƒä¸åƒæ°´é‚£æ ·å±é™©ã€‚çœŸä¸é”™ï¼Œâ€è¨å§†è¯´ã€‚  \\n'\n",
      "           'ä»–ä»¬çœ‹äº†ä¸€ä¼šå„¿æµ·è±šã€‚æ¯æ¬¡æµ·è±šè·³è·ƒã€æ—‹è½¬æˆ–æŒ¥æ‰‹æ—¶ï¼Œä»–ä»¬éƒ½é¼“æŒæ¬¢å‘¼ã€‚ä»–ä»¬å¾®ç¬‘ç€æŒ¥æ‰‹å›åº”ã€‚ä»–ä»¬æ„Ÿåˆ°å¿«ä¹å’Œå…´å¥‹ã€‚  \\n'\n",
      "           'ä»–ä»¬é‚£å¤©å­¦åˆ°äº†å¾ˆå¤šæ–°ä¸œè¥¿ã€‚ä»–ä»¬æ˜ç™½äº†æµ·æ´‹ä¸ä»…å±é™©ï¼Œè¿˜æœ‰å¾ˆå¤šç¾å¦™çš„åœ°æ–¹ã€‚ä»–ä»¬å­¦åˆ°åœ¨æµ·æ»©ä¸Šæœ‰å¾ˆå¤šä¸œè¥¿å¯ä»¥çœ‹ã€å¯ä»¥åšå’Œå¯ä»¥äº«å—ã€‚ä»–ä»¬å­¦åˆ°å¯ä»¥åœ¨ä¸ä¸‹æ°´çš„æƒ…å†µä¸‹ç©å¾—å¼€å¿ƒã€‚ä»–ä»¬å­¦åˆ°å¯ä»¥äº¤æ–°æœ‹å‹ï¼Œçœ‹åˆ°æ–°åŠ¨ç‰©ã€‚ä»–ä»¬å­¦åˆ°å¯ä»¥ä¸ºæµ·è±šé¼“æŒã€‚'}\n",
      "{'input': 'ç‰¹å¾ï¼šå¯¹è¯ï¼Œé“å¾·ä»·å€¼\\n'\n",
      "          'éšæœºå¥å­ï¼šä¸€å¤©ï¼Œç­å°¼çœ‹åˆ°åœ°ä¸Šæœ‰ä¸€æŠŠæ¢³å­ã€‚\\n'\n",
      "          'æ‘˜è¦ï¼šå…”å­ç­å°¼åœ¨æ„å¤–æ‹¿èµ°äº†ä¸€æŠŠå±äºå°å¥³å­©çš„æ¢³å­ï¼Œå¹¶åæ¥é‡åˆ°ä¸€åªæ­»é¸Ÿåï¼Œæ˜ç™½äº†è¯šå®å’Œå°Šé‡ç”Ÿå‘½çš„é‡è¦æ€§ã€‚',\n",
      " 'instruction': 'æŒ‰ç…§ä¸‹é¢è¾“å…¥çš„çº¦æŸç”Ÿæˆæ•…äº‹',\n",
      " 'output': 'ä»å‰ï¼Œæœ‰ä¸€åªå«ç­å°¼çš„å…”å­ã€‚ç­å°¼å–œæ¬¢æ•´å¤©è·³è·ƒå’Œç©è€ã€‚ä¸€å¤©ï¼Œç­å°¼çœ‹åˆ°åœ°ä¸Šæœ‰ä¸€æŠŠæ¢³å­ã€‚ä»–è§‰å¾—æŒºæœ‰æ„æ€çš„ï¼Œå†³å®šæ¡èµ·æ¥ã€‚  \\n'\n",
      "           'å½“ç­å°¼åœ¨æ¢³ç†è‡ªå·±çš„æ¯›å‘æ—¶ï¼Œä»–å¬åˆ°ä¸€ä¸ªå£°éŸ³è¯´ï¼šâ€œå˜¿ï¼Œå…”å­ï¼é‚£æŠŠæ¢³å­æ˜¯æˆ‘çš„ï¼â€è¿™æ˜¯ä¸€ä¸ªå°å¥³å­©ï¼Œå¥¹æ‰äº†æ¢³å­ã€‚ç­å°¼å› ä¸ºæ²¡æœ‰è¯¢é—®å°±æ‹¿èµ°äº†æ¢³å­è€Œæ„Ÿåˆ°å¾ˆä¸å¥½æ„æ€ï¼Œè¿…é€ŸæŠŠæ¢³å­è¿˜ç»™äº†å¥¹ã€‚  \\n'\n",
      "           'å°å¥³å­©å¾ˆé«˜å…´ï¼Œè°¢ç­å°¼çš„è¯šå®ã€‚å¥¹å‘Šè¯‰ä»–ï¼Œåœ¨æ‹¿ä¸œè¥¿ä¹‹å‰ä¸€å®šè¦å…ˆé—®æ˜¯å¾ˆé‡è¦çš„ã€‚ç­å°¼ä¸ºè‡ªå·±åšå¯¹äº†äº‹æƒ…è€Œæ„Ÿåˆ°è‡ªè±ªï¼Œé«˜é«˜å…´å…´åœ°è·³å¼€äº†ã€‚  \\n'\n",
      "           'å½“ä»–è·³æ¥è·³å»æ—¶ï¼Œç­å°¼çœ‹åˆ°åœ°ä¸Šæœ‰ä¸€åªæ­»é¸Ÿã€‚ä»–æƒ³èµ·äº†å°å¥³å­©çš„è¯ï¼ŒçŸ¥é“å°Šé‡ç”Ÿå‘½æ˜¯å¾ˆé‡è¦çš„ï¼Œå³ä½¿å®ƒä»¬å·²ç»ä¸å†æ´»ç€ã€‚ç­å°¼ä¸ºé‚£åªé¸Ÿé»˜å“€ï¼Œç»§ç»­ä»–çš„è·¯ç¨‹ï¼Œå¿ƒé‡Œæ„Ÿæ¿€è‡ªå·±å­¦åˆ°çš„æ•™è®­ã€‚'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    pprint(final_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å°ç»“\n",
    "1. åŸºäº`TinyStories`çš„`Instruct`æ•°æ®è¿›è¡ŒæŒ‡ä»¤ç»„åˆå±‚é¢å‡è¡¡çš„é‡‡æ ·ï¼Œè·å¾—äº†15000æ¡åŸå§‹æ•°æ®\n",
    "2. æ„é€ äº†ç¿»è¯‘å‡½æ•°ï¼Œå¼‚æ­¥ä½¿ç”¨å´æ©è¾¾è€å¸ˆçš„`translation-agent`å¯¹æ•°æ®è¿›è¡Œç¿»è¯‘\n",
    "3. åŸºäºç¿»è¯‘åçš„æ•°æ®ï¼Œæ„é€ äº†ç»å…¸æ ¼å¼çš„`SFT`æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigmodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
