# ä»é›¶æ‰‹æ“ä¸­æ–‡å¤§æ¨¡å‹ï½œğŸš€ Day07

## SFT æ•°æ®å‡†å¤‡

`TinyStories`æ•°æ®é›†å…¶å®ä¹Ÿæä¾›äº†[Instructæ•°æ®](https://huggingface.co/datasets/roneneldan/TinyStoriesInstruct)ï¼Œæˆ‘å¯ä»¥åŸºäºè¿™ä¸ªæ•°æ®é›†åœ¨ä¹‹å‰çš„é¢„è®­ç»ƒæ¨¡å‹ä¸Šè¿›è¡ŒæŒ‡ä»¤å¾®è°ƒã€‚

å…ˆçœ‹çœ‹æ•°æ®é›†çš„æ ¼å¼ï¼š


```python
! head -10 ../../Data/TinyStoriesInstruct/TinyStories-Instruct-train.txt
```

    Features: Dialogue
    Words: quit, oak, gloomy
    Summary: Sara and Ben were playing in the park, but Sara wanted to go home because it was cold and dark. Ben convinced her to stay and play, but eventually agreed to go home and have hot cocoa.
    Story: 
    
    Sara and Ben were playing in the park. They liked to climb the big oak tree and pretend they were birds. They made nests with leaves and twigs and sang songs.
    But today, the sky was gloomy and the wind was cold. Sara felt sad and cold. She wanted to go home and have some hot cocoa.
    "Ben, I want to quit," she said. "It's too cold and dark. Let's go home."
    Ben looked at Sara and frowned. He liked the oak tree and the park. He wanted to stay and play.
    "No, Sara, don't quit," he said. "It's fun here. Look, there's a squirrel. Let's chase it."


è¿™äº›æŒ‡ä»¤æœ‰å››ç§ç±»å‹ï¼š
1. ä¸€ä¸ªå•è¯åˆ—è¡¨ï¼ŒåŒ…å«åœ¨æ•…äº‹ä¸­ã€‚
2. ä¸€ä¸ªå¥å­ï¼Œåº”è¯¥å‡ºç°åœ¨æ•…äº‹çš„æŸä¸ªåœ°æ–¹ã€‚
3. ä¸€ä¸ªç‰¹å¾åˆ—è¡¨ï¼ˆå¯èƒ½çš„ç‰¹å¾ï¼šå¯¹è¯ã€åç»“å±€ã€é“å¾·ä»·å€¼ã€æƒ…èŠ‚è½¬æŠ˜ã€ä¼ç¬”ã€å†²çªï¼‰ã€‚
4. ä¸€ä¸ªç®€çŸ­çš„æ€»ç»“ï¼ˆ1-2è¡Œï¼‰ã€‚

ç°åœ¨é¢ä¸´ä¸¤ä¸ªé—®é¢˜ï¼š
- æ•°æ®é›†æ˜¯è‹±æ–‡çš„ï¼Œæˆ‘éœ€è¦æƒ³åŠæ³•ç»™æ•´æˆä¸­æ–‡çš„ã€‚
- æ•°æ®é›†çš„å½¢å¼å’Œä¸»æµçš„SFTæ•°æ®é›†ä¸å¤ªä¸€æ ·ï¼Œéœ€è¦åšä¸€äº›é€‚é…ã€‚

  > ä¸ªäººç†è§£è¿™é‡Œæ˜¯å› ä¸ºè¿™é‡Œçš„æŒ‡ä»¤ç›¸å¯¹å•ä¸€ï¼ˆç”Ÿæˆæ•…äº‹ï¼‰ï¼Œåªæ˜¯çº¦æŸæœ‰ä¸€äº›åŒºåˆ«ï¼Œæ‰€ä»¥ä½œè€…é‡‡å–äº†ç®€å•çš„æ‹¼æ¥æ–¹å¼ã€‚
  >
  > è¿™é‡Œå‡ºäºå­¦ä¹ çš„ç›®çš„è¿˜æ˜¯å¾€ä¸»æµçš„SFTæ•°æ®é›†ä¸Šé æ‹¢ã€‚

### å´æ©è¾¾è€å¸ˆçš„ç¿»è¯‘Agentæµ‹è¯•

è¿™é‡Œç›´æ¥è¯•äº†ä¸‹[å´æ©è¾¾è€å¸ˆçš„translation-agent](https://github.com/andrewyng/translation-agent)é¡¹ç›®ï¼ˆ`translation-agent.py`æ–‡ä»¶ï¼‰ï¼Œä½¿ç”¨çš„æ˜¯`gpt-4o-mini`çš„`api`ï¼ˆä¹Ÿå°è¯•è¿‡`Ollama`æœ¬åœ°éƒ¨ç½²çš„`qwen14b`ã€`qwen7b`ï¼Œç›¸å¯¹æ¥è¯´ä¸å¤ªç¨³å®šï¼‰ã€‚

å¯ä»¥çœ‹åˆ°è¿™é‡Œå•æ¬¡ç¿»è¯‘çš„è€—æ—¶åœ¨10ç§’å·¦å³ï¼ˆå› ä¸ºå•è¯ç¿»è¯‘çš„æ—¶å€™`agent`é€»è¾‘é‡Œæœ‰å¤šæ¬¡`api`è°ƒç”¨ï¼‰ï¼Œå› æ­¤è¿™é‡Œä¸ºäº†åé¢èƒ½å¤Ÿå¹¶å‘è°ƒç”¨åˆ·æ•°æ®ï¼Œæˆ‘å°†ä»£ç å…¨éƒ¨æ”¹é€ æˆäº†`async`çš„å¼‚æ­¥è°ƒç”¨ã€‚

å¤§å®¶å¦‚æœæœ‰å…¶ä»–çš„ç¿»è¯‘`api`æˆ–è€…æ¨¡å‹ä¹Ÿå¯ä»¥æ›¿æ¢ï¼Œè¿™é‡Œçº¯å±å¿ƒè¡€æ¥æ½®ç©ä¸€ç©å„¿ã€‚

`translation-agent`é¡¹ç›®å…¶å®åªæœ‰ä¸€ä¸ª`utils.py`æ–‡ä»¶ï¼Œä½†å› ä¸ºå¤ªé•¿äº†ï¼Œè¿™é‡Œå°±ä¸æŠŠæ”¹é€ åçš„ä»£ç è´´å‡ºæ¥äº†ï¼Œæœ‰å…´è¶£çš„åŒå­¦å¯ä»¥å»ä»“åº“é‡ŒæŸ¥çœ‹ã€‚


```python
from translation_agent import translate

text = """
Random sentence: They are very excited and want to fly too.
Features: Dialogue
Summary: Tom and Anna are excited to go on a holiday with their parents, and they fly on a big plane to a place with sun and sand.
Story: 
Tom and Anna are brother and sister. They like to play with their toys and read books. They are very happy because they are going on a holiday with their mum and dad. They will fly on a big plane to a place with a lot of sun and sand.
The day of the holiday comes and they pack their bags. They go to the airport and wait for their plane. They see many other planes flying in the sky. They are very excited and want to fly too.
"Look, Anna, that plane is so big and fast!" Tom says.
"Yes, Tom, and it has wings and a tail. I wonder where it is going," Anna says.
They hear their mum call them. "Come on, kids, it's time to board our plane. We have to show our tickets and go through the gate."
They follow their mum and dad and get on their plane. They find their seats and buckle their belts. They look out the window and see the ground and the cars and the people. They hear the pilot say something on the speaker.
"Hello, everyone, this is your pilot speaking. Welcome aboard flight 123 to Sunny Beach. We are ready to take off. Please sit back and enjoy the flight."
The plane starts to move and makes a loud noise. Tom and Anna feel the plane go faster and faster. They see the ground get smaller and smaller. They see the clouds get closer and closer. They are flying!
"Wow, Anna, we are flying! We are in the sky!" Tom says.
"I know, Tom, it's amazing! We are so high! Look, there is the sun!" Anna says.
They smile and laugh and clap their hands. They are not sad at all. They are very happy. They are flying to their holiday.
"""


result = await translate(
    source_lang="English",
    target_lang="Chinese",
    source_text=text,
    country="China",
)
print(result)
```

    ic| num_tokens_in_text: 416
    ic| 'Translating text as a single chunk'


    éšæœºå¥å­ï¼šä»–ä»¬éå¸¸å…´å¥‹ï¼Œä¹Ÿæƒ³é£ã€‚  
    ç‰¹ç‚¹ï¼šå¯¹è¯  
    æ‘˜è¦ï¼šæ±¤å§†å’Œå®‰å¨œå…´å¥‹åœ°å’Œçˆ¶æ¯ä¸€èµ·å»åº¦å‡ï¼Œä»–ä»¬ä¹˜åä¸€æ¶å¤§é£æœºé£å¾€é˜³å…‰æ˜åªšã€æ²™æ»©ç»†è…»çš„åœ°æ–¹ã€‚  
    æ•…äº‹ï¼š  
    æ±¤å§†å’Œå®‰å¨œæ˜¯å…„å¦¹ã€‚ä»–ä»¬å–œæ¬¢ç©ç©å…·å’Œè¯»ä¹¦ã€‚ä»–ä»¬éå¸¸å¼€å¿ƒï¼Œå› ä¸ºä»–ä»¬è¦å’Œçˆ¸çˆ¸å¦ˆå¦ˆä¸€èµ·å»åº¦å‡ã€‚ä»–ä»¬å°†ä¹˜åä¸€æ¶å¤§é£æœºå»ä¸€ä¸ªé˜³å…‰æ˜åªšã€æ²™æ»©ç»†è…»çš„åœ°æ–¹ã€‚  
    åº¦å‡çš„æ—¥å­åˆ°äº†ï¼Œä»–ä»¬å¼€å§‹æ•´ç†è¡Œæã€‚ä»–ä»¬å»æœºåœºï¼Œç­‰å¾…ä»–ä»¬çš„é£æœºã€‚ä»–ä»¬çœ‹åˆ°è®¸å¤šå…¶ä»–é£æœºåœ¨å¤©ç©ºä¸­é£ã€‚ä»–ä»¬éå¸¸å…´å¥‹ï¼Œä¹Ÿæƒ³é£ã€‚  
    â€œçœ‹ï¼Œå®‰å¨œï¼Œé‚£æ¶é£æœºåˆå¤§åˆå¿«ï¼â€æ±¤å§†è¯´ã€‚  
    â€œæ˜¯çš„ï¼Œæ±¤å§†ï¼Œå®ƒæœ‰ç¿…è†€å’Œå°¾å·´ã€‚æˆ‘æƒ³çŸ¥é“å®ƒè¦å»å“ªé‡Œï¼Œâ€å®‰å¨œè¯´ã€‚  
    ä»–ä»¬å¬åˆ°å¦ˆå¦ˆå«ä»–ä»¬ã€‚â€œå¿«ç‚¹ï¼Œå­©å­ä»¬ï¼Œå·®ä¸å¤šè¯¥ç™»æœºäº†ã€‚æˆ‘ä»¬å¿…é¡»å‡ºç¤ºæœºç¥¨ï¼Œç„¶åé€šè¿‡ç™»æœºå£ã€‚â€  
    ä»–ä»¬è·Ÿç€çˆ¸çˆ¸å¦ˆå¦ˆä¸Šäº†é£æœºã€‚ä»–ä»¬æ‰¾åˆ°è‡ªå·±çš„åº§ä½ï¼Œç³»å¥½å®‰å…¨å¸¦ã€‚ä»–ä»¬æœ›å‘çª—å¤–ï¼Œçœ‹åˆ°åœ°é¢ã€æ±½è½¦å’Œäººã€‚ä»–ä»¬å¬åˆ°é£è¡Œå‘˜åœ¨æ‰¬å£°å™¨ä¸Šè¯´è¯ã€‚  
    â€œå¤§å®¶å¥½ï¼Œæˆ‘æ˜¯ä½ ä»¬çš„æœºé•¿ã€‚æ¬¢è¿ä¹˜å123èˆªç­å‰å¾€é˜³å…‰æµ·æ»©ã€‚æˆ‘ä»¬å‡†å¤‡èµ·é£ã€‚è¯·åå¥½ï¼Œäº«å—æ—…ç¨‹ã€‚â€  
    é£æœºå¼€å§‹ç§»åŠ¨ï¼Œå‘å‡ºè½°é¸£çš„å£°éŸ³ã€‚æ±¤å§†å’Œå®‰å¨œæ„Ÿè§‰é£æœºè¶Šæ¥è¶Šå¿«ã€‚ä»–ä»¬çœ‹åˆ°åœ°é¢å˜å¾—è¶Šæ¥è¶Šå°ã€‚äº‘æœµè¶Šæ¥è¶Šè¿‘ã€‚ä»–ä»¬åœ¨é£ï¼  
    â€œå“‡ï¼Œå®‰å¨œï¼Œæˆ‘ä»¬åœ¨é£ï¼æˆ‘ä»¬åœ¨å¤©ç©ºä¸­ï¼â€æ±¤å§†è¯´ã€‚  
    â€œæˆ‘çŸ¥é“ï¼Œæ±¤å§†ï¼Œå¤ªç¥å¥‡äº†ï¼æˆ‘ä»¬è¿™ä¹ˆé«˜ï¼çœ‹ï¼Œé‚£é‡Œæ˜¯å¤ªé˜³ï¼â€å®‰å¨œè¯´ã€‚  
    ä»–ä»¬å¾®ç¬‘ã€æ¬¢ç¬‘ï¼Œæ‹æ‰‹æ¬¢å‘¼ã€‚ä»–ä»¬ä¸€ç‚¹éƒ½ä¸éš¾è¿‡ã€‚ä»–ä»¬éå¸¸å¿«ä¹ã€‚ä»–ä»¬æ­£åœ¨é£å¾€åº¦å‡çš„åœ°æ–¹ã€‚


### æ•°æ®é‡‡æ ·

æˆ‘å…ˆçœ‹çœ‹è®­ç»ƒé›†æœ‰å¤šå°‘æ¡æ•°æ®ï¼Œå¯ä»¥å‘ç°æ–‡æœ¬éƒ½æ˜¯ä»¥`<|endoftext|>`ç»“å°¾çš„ï¼Œæ‰€ä»¥é€šè¿‡ç»Ÿè®¡`endoftext`çš„ä¸ªæ•°å°±å¯ä»¥çŸ¥é“æ•°æ®é›†çš„æ¡æ•°ã€‚


```python
! grep -o "endoftext" ../../Data/TinyStoriesInstruct/TinyStories-Instruct-train.txt  | wc -l 
```

    2476532


æ¥è¿‘250wçš„é‡çº§æœ‰ç‚¹å¤§ï¼ˆå› ä¸ºå¾®è½¯çš„è®ºæ–‡é‡Œæ˜¯ç›´æ¥åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šåšçš„`pretrain`çš„ï¼‰ã€‚

å…¶å®å¾ˆå¤šç ”ç©¶è¡¨æ˜ï¼Œ`SFT`æ•°æ®çš„é‡çº§ä¸é‡è¦ï¼Œè´¨é‡å¤Ÿé«˜çš„æ—¶å€™å³ä½¿å¾ˆå°‘çš„æ•°æ®ä¹Ÿèƒ½è®­ç»ƒå‡ºå¾ˆå¥½çš„æ•ˆæœã€‚

æ‰€ä»¥è¿™é‡Œæˆ‘æ‰“ç®—éšæœºæŠ½å–11000æ¡æ•°æ®æ¥è¯•è¯•ã€‚

æˆ‘çš„ç­–ç•¥å¦‚ä¸‹ï¼š
1. éå†`train`æ•°æ®é›†ï¼Œè®©å››ç±»æŒ‡ä»¤çš„ç»„åˆå°½é‡å‡è¡¡ï¼ˆéœ€è¦å…ˆç»Ÿè®¡æŒ‡ä»¤ç»„åˆçš„çš„åˆ†å¸ƒï¼‰
2. ç”¨å¾—åˆ°çš„11000æ¡æ•°æ®è°ƒç”¨ä¸Šé¢çš„`translation-agent`è¿›è¡Œç¿»è¯‘
3. å°†ç¿»è¯‘åçš„æ•°æ®æ•´ç†æˆ`SFT`æ•°æ®é›†çš„`json`æ ¼å¼

å…ˆæ¥åšæ•°æ®çš„é‡‡æ ·ï¼š


```python
from collections import Counter
import random


def count_field_combinations(file_path):
    with open(file_path, "r", encoding="utf-8") as file:
        content = file.read()

    blocks = content.split("<|endoftext|>")
    combinations = []

    for block in blocks:
        fields = set()
        if "Words:" in block:
            fields.add("Words")
        if "Random sentence:" in block:
            fields.add("Random sentence")
        if "Features:" in block:
            fields.add("Features")
        if "Summary:" in block:
            fields.add("Summary")

        if fields:  # åªæœ‰å½“å­—æ®µä¸ä¸ºç©ºæ—¶æ‰æ·»åŠ ç»„åˆ
            combinations.append(frozenset(fields))

    return Counter(combinations)


def sample_data(file_path, total_samples=11000):
    with open(file_path, "r", encoding="utf-8") as file:
        content = file.read()

    blocks = content.split("<|endoftext|>")
    blocks = [block.strip() for block in blocks if block.strip()]  # ç§»é™¤ç©ºå—

    combinations = count_field_combinations(file_path)
    combination_more_than_1 = {k: v for k, v in combinations.items() if v > 1}
    samples_per_combination = total_samples // len(combination_more_than_1)

    sampled_data = []
    for combination in combinations:
        matching_blocks = [
            block for block in blocks if set(get_fields(block)) == set(combination)
        ]
        sampled_data.extend(
            random.sample(
                matching_blocks, min(samples_per_combination, len(matching_blocks))
            )
        )

    return sampled_data


def get_fields(block):
    fields = set()
    if "Words:" in block:
        fields.add("Words")
    if "Random sentence:" in block:
        fields.add("Random sentence")
    if "Features:" in block:
        fields.add("Features")
    if "Summary:" in block:
        fields.add("Summary")
    return fields
```

æ‰§è¡Œä¸€ä¸‹çœ‹çœ‹æ•ˆæœï¼ˆä¸ºäº†æœ‰å¤‡æ— æ‚£ï¼Œå¤šé‡‡æ ·äº†5000æ¡æ•°æ®ï¼‰ï¼Œè€—æ—¶1-2åˆ†é’Ÿï¼Œè‚¯å®šè¿˜æœ‰ä¼˜åŒ–ç©ºé—´ï¼Œä½†æ˜¯å¯ä»¥æ¥å—ã€‚

åŒæ—¶å°†é‡‡æ ·åçš„æ•°æ®ä¿å­˜ä¸º`pkl`æ–‡ä»¶ï¼Œæ–¹ä¾¿åç»­ä½¿ç”¨ã€‚


```python
import pickle

# sft_raw = sample_data(
#     "../../Data/TinyStoriesInstruct/TinyStories-Instruct-train.txt", 15000
# )
sft_raw = pickle.load(open("sft_raw.pkl", "rb"))
print(f"é‡‡æ ·æ•°æ®æ€»æ•°: {len(sft_raw)}")

# pickle.dump(sft_raw, open("sft_raw.pkl", "wb"))
```

    é‡‡æ ·æ•°æ®æ€»æ•°: 15001


### æ‰¹é‡ç¿»è¯‘

æ¥ä¸‹æ¥å°±å¯ä»¥è°ƒç”¨`translation-agent`è¿›è¡Œç¿»è¯‘äº†ã€‚

è¿™é‡Œæˆ‘é™¤äº†ç”¨å¼‚æ­¥åŠ é€Ÿï¼Œè¿˜ä½¿ç”¨äº†`json`æ–‡ä»¶ç¼“å­˜æ¥é¿å…é‡å¤ç¿»è¯‘ï¼ˆ`gpt-4o-mini`çš„`api`ä¹Ÿä¸ç®—ä¾¿å®œï¼Œèƒ½çœåˆ™çœï¼‰ã€‚


```python
import json
import aiofiles
import asyncio

cache_file = "translation_cache.json"


async def translate_and_cache(block, cache, semaphore):
    cache_key = hash(block)

    if str(cache_key) in cache:
        return cache[str(cache_key)]

    async with semaphore:
        try:
            result = await translate(
                source_lang="English",
                target_lang="Chinese",
                source_text=block,
                country="China",
            )
            cache[str(cache_key)] = result
            return result
        except Exception as e:
            print(f"ç¿»è¯‘å¤±è´¥: {e}")
            return None


async def batch_translate(sampled_data, cache_file, max_workers=10):
    translated_data = []

    try:
        async with aiofiles.open(cache_file, "r") as f:
            cache = json.loads(await f.read())
    except (FileNotFoundError, json.JSONDecodeError):
        cache = {}

    semaphore = asyncio.Semaphore(max_workers)
    tasks = [translate_and_cache(block, cache, semaphore) for block in sampled_data]
    results = await asyncio.gather(*tasks)

    translated_data = [result for result in results if result]

    async with aiofiles.open(cache_file, "w") as f:
        await f.write(json.dumps(cache, ensure_ascii=False, indent=2))

    return translated_data


translated_data = await batch_translate(sft_raw, cache_file, max_workers=100)
```

ä½¿ç”¨äº†100è·¯çš„å¹¶å‘ï¼Œç¿»è¯‘äº†15000æ¡æ•°æ®ï¼Œè€—æ—¶48åˆ†é’Ÿï¼Œä¹Ÿå°±æ˜¯å¤§æ¦‚æ¯åˆ†é’Ÿç¿»è¯‘300æ¡æ•°æ®ã€‚

### åç»­å¤„ç†

ç¿»è¯‘å®Œæˆäº†ï¼Œæœ€åä¸€æ­¥å°±æ˜¯å°†æ•°æ®æ•´ç†æˆ`SFT`æ•°æ®é›†çš„æ ¼å¼ã€‚

ï¼ˆè¿™é‡Œè¿˜å‘ç°äº†ä¸ªå°é—®é¢˜ï¼Œç¿»è¯‘ç»Ÿä¸€å°†**æ€»ç»“**å­—æ®µæ”¾åˆ°äº†æœ€åï¼Œå¯¼è‡´é¡ºåºå‡ºç°äº†é—®é¢˜ï¼Œæ‰€ä»¥è¿™é‡Œéœ€è¦å…ˆå¤„ç†ä¸€ä¸‹ã€‚ï¼‰


```python
import itertools
import json
import random
from collections import Counter
from pprint import pprint

instruction_template = "æŒ‰ç…§ä¸‹é¢è¾“å…¥çš„çº¦æŸç”Ÿæˆæ•…äº‹"


def process_translated_data(input_file):
    with open(input_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    processed_data = []
    constraint_keys = Counter()

    for key, value in data.items():
        if "æ•…äº‹ï¼š" not in value:
            continue
        parts = value.split("æ•…äº‹ï¼š")

        if len(parts) == 2:
            input_text = parts[0].strip()
            output_text = parts[1].strip()

            # æå–çº¦æŸæè¿°æ–‡æœ¬çš„å…³é”®å­—æ®µ
            lines = input_text.split("\n")
            for line in lines:
                if "ï¼š" in line:
                    key, _ = line.split("ï¼š", 1)
                    constraint_keys[key.strip()] += 1

            processed_item = {
                "instruction": instruction_template,
                "input": f"{input_text}",
                "output": output_text,
            }

            processed_data.append(processed_item)
    # æ ¹æ®constraint_keysçš„é¢‘ç‡æ’åºï¼Œé€‰å–å‡ºç°é¢‘ç‡å¤§äº10çš„å…³é”®å­—
    constraint_keys = {k: v for k, v in constraint_keys.items() if v > 10}
    return constraint_keys, processed_data
```


```python
constraint_keys, processed_data = process_translated_data("translation_cache.json")
```


```python
keywords_normalization = {
    "è¯æ±‡": "è¯æ±‡",
    "å…³é”®è¯": "è¯æ±‡",
    "å•è¯": "è¯æ±‡",
    "è¯è¯­": "è¯æ±‡",
    "è¯": "è¯æ±‡",
    "å­—": "è¯æ±‡",
    "ç‰¹å¾": "ç‰¹å¾",
    "ç‰¹ç‚¹": "ç‰¹å¾",
    "æ•…äº‹ç‰¹ç‚¹": "ç‰¹å¾",
    "æ•…äº‹ç‰¹å¾": "ç‰¹å¾",
    "å¯¹è¯ç‰¹ç‚¹": "ç‰¹å¾",
    "ä¸»é¢˜": "ç‰¹å¾",
    "éšæœºå¥å­": "éšæœºå¥å­",
    "éšä¾¿ä¸€å¥è¯": "éšæœºå¥å­",
    "éšæœºä¸€å¥è¯": "éšæœºå¥å­",
    "éšæœºå¥": "éšæœºå¥å­",
    "éšæœºçš„ä¸€å¥è¯": "éšæœºå¥å­",
    "éšæœºçš„å¥å­": "éšæœºå¥å­",
    "éšæœºå¥å­æ˜¯": "éšæœºå¥å­",
    "éšä¾¿è¯´ä¸€å¥": "éšæœºå¥å­",
    "éšä¾¿ä¸€å¥": "éšæœºå¥å­",
    "éšæœºå¥å­ç¤ºä¾‹": "éšæœºå¥å­",
    "æ‘˜è¦": "æ‘˜è¦",
    "æ€»ç»“": "æ‘˜è¦",
    "æ•…äº‹æ¦‚è¦": "æ‘˜è¦",
}
```


```python
def split_data(data, keys):
    result = []
    current_key = None
    current_content = ""

    for line in data.split("\n"):
        line = line.strip()
        if any(key in line for key in keys):
            if current_key:
                result.append((current_key, current_content.strip()))
            for key in keys:
                if key in line:
                    current_key, current_content = line.split(key, 1)
                    current_key = key.strip()
                    current_content = current_content.strip().lstrip("ï¼š").strip()
                    break
        else:
            current_content += " " + line

    if current_key:
        result.append((current_key, current_content.strip()))

    return result


def filter_and_normalize(
    processed_data, constraint_keys, output_file, expand_data=True
):
    final_data = []
    for item in processed_data:
        input_text = item["input"]
        output_text = item["output"]
        has_keyword = False
        for keyword in keywords_normalization:
            if f"{keyword}ï¼š" in output_text:
                content = output_text.split(f"{keyword}ï¼š")[1].strip()
                input_text += f"\n{keyword}ï¼š{content}"
                output_text = output_text.split(f"{keyword}ï¼š")[0].strip()
                has_keyword = True
            if f"{keyword}ï¼š" in input_text:
                input_text = input_text.replace(
                    f"{keyword}ï¼š", f"{keywords_normalization[keyword]}ï¼š"
                )
                has_keyword = True
        if not has_keyword:
            continue

        # æ•°æ®å¢å¼º
        if expand_data:
            input_tuple_list = split_data(input_text, keywords_normalization)
            if not input_tuple_list:
                continue

            for permutation in itertools.permutations(input_tuple_list):
                new_item = {
                    "instruction": instruction_template,
                    "input": "\n".join(
                        [f"{key}ï¼š{value}" for key, value in permutation]
                    ),
                    "output": output_text,
                }
                final_data.append(new_item)
        else:
            item.update({"input": input_text, "output": output_text})
            final_data.append(item)

    # å¯¹ç»“æœåšä¸€ä¸ªæ‰“ä¹±
    random.shuffle(final_data)
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)

    return final_data
```


```python
final_data = filter_and_normalize(
    processed_data,
    keywords_normalization,
    "../../Data/TinyStoriesInstruct/sft_data_v2.json",
    True,
)
```

çœ‹ä¸€çœ‹å¤„ç†çš„ç»“æœï¼Œè¿™æ ·å°±å’Œç»å…¸çš„`SFT`æ•°æ®æ ¼å¼ä¸€è‡´äº†ã€‚


```python
for i in range(5):
    pprint(final_data[i])
```

    {'input': 'éšæœºå¥å­ï¼šéšæœºå¥å­ï¼šè’‚å§†çš„ç½‘çƒæ°´å¹³è¶Šæ¥è¶Šå¥½ï¼Œä½†æœ‰æ—¶ä»–åœ¨é”™è¿‡çƒçš„æ—¶å€™ä¼šæ„Ÿåˆ°ä¸è€çƒ¦ã€‚\n'
              'ç‰¹å¾ï¼šå¯¹è¯\n'
              'æ‘˜è¦ï¼šè’‚å§†å’Œä»–çš„çˆ¸çˆ¸ä¸€èµ·æ‰“ç½‘çƒï¼Œä½†å½“è’‚å§†é”™è¿‡çƒæ—¶ä¼šæ„Ÿåˆ°ä¸è€çƒ¦ã€‚ä»–çš„çˆ¸çˆ¸é¼“åŠ±ä»–åšæŒç»ƒä¹ ï¼Œæœ€ç»ˆè’‚å§†æˆåŠŸæŠŠçƒæ‰“è¿‡äº†ç½‘ï¼Œå¹¶ä¸ºè‡ªå·±æ„Ÿåˆ°éª„å‚²ã€‚',
     'instruction': 'æŒ‰ç…§ä¸‹é¢è¾“å…¥çš„çº¦æŸç”Ÿæˆæ•…äº‹',
     'output': 'ä»å‰ï¼Œæœ‰ä¸ªå«è’‚å§†çš„å°ç”·å­©ã€‚è’‚å§†å–œæ¬¢å’Œä»–çš„çˆ¸çˆ¸æ‰“ç½‘çƒã€‚ä»–ä»¬ä¼šå»å…¬å›­ï¼Œæ¥å›å‡»çƒã€‚è’‚å§†çš„ç½‘çƒæ°´å¹³è¶Šæ¥è¶Šå¥½ï¼Œä½†æœ‰æ—¶ä»–åœ¨é”™è¿‡çƒçš„æ—¶å€™ä¼šæ„Ÿåˆ°ä¸è€çƒ¦ã€‚  \n'
               'ä¸€å¤©ï¼Œè’‚å§†å’Œä»–çš„çˆ¸çˆ¸åœ¨æ‰“ç½‘çƒï¼Œè’‚å§†é”™è¿‡äº†å¾ˆå¤šæ¬¡çƒã€‚ä»–å˜å¾—å¾ˆä¸è€çƒ¦ï¼Œç”šè‡³å“­äº†èµ·æ¥ã€‚ä»–çš„çˆ¸çˆ¸è¯´ï¼šâ€œåˆ«æ‹…å¿ƒï¼Œè’‚å§†ã€‚ä½ é€šè¿‡ç»ƒä¹ ä¼šå˜å¾—æ›´å¥½çš„ã€‚â€  \n'
               'çˆ¸çˆ¸ç»™è’‚å§†å‘äº†ä¸ªçƒï¼Œè’‚å§†æŠŠçƒæ‰“è¿‡äº†ç½‘ã€‚ä»–é«˜å…´å¾—ä¸å¾—äº†ï¼è’‚å§†è¯´ï¼šâ€œæˆ‘æˆåŠŸäº†ï¼Œçˆ¸çˆ¸ï¼â€  \n'
               'ä»–çš„çˆ¸çˆ¸å¾®ç¬‘ç€è¯´ï¼šâ€œæ²¡é”™ï¼Œä½ æˆåŠŸäº†ï¼ç°åœ¨æˆ‘ä»¬ç»§ç»­ç©ï¼Œäº«å—å…¶ä¸­çš„ä¹è¶£ã€‚â€è’‚å§†æ„Ÿåˆ°éå¸¸è‡ªè±ªï¼Œä¸€ç›´æ‰“çƒï¼Œç›´åˆ°è¯¥å›å®¶çš„æ—¶å€™ã€‚'}
    {'input': 'è¯æ±‡ï¼šæ’’è°ï¼Œæ‰“æ¶ï¼Œå¤§\n'
              'æ‘˜è¦ï¼šè‰¾è‰è¿™åªå¤§è±¡å¸®åŠ©æœ‹å‹ä»¬è’‚ç±³å’Œè¨ç±³å’Œè§£ï¼Œå¼ºè°ƒäº†å‹è°Šå’Œä¸€èµ·ç©çš„é‡è¦æ€§ã€‚\n'
              'éšæœºå¥å­ï¼šè‰¾è‰å’Œå¥¹çš„æœ‹å‹ä»¬ä½åœ¨ä¸€ç‰‡å¤§ä¸›æ—é‡Œã€‚\n'
              'ç‰¹å¾ï¼šå¯¹è¯',
     'instruction': 'æŒ‰ç…§ä¸‹é¢è¾“å…¥çš„çº¦æŸç”Ÿæˆæ•…äº‹',
     'output': 'ä»å‰ï¼Œæœ‰ä¸€åªå«è‰¾è‰çš„å¤§è±¡ã€‚è‰¾è‰å’Œå¥¹çš„æœ‹å‹ä»¬ä½åœ¨ä¸€ç‰‡å¤§ä¸›æ—é‡Œã€‚ä¸€å¤©ï¼Œè‰¾è‰çœ‹åˆ°å¥¹çš„æœ‹å‹è€è™è’‚ç±³èººåœ¨åœ°ä¸Šã€‚  \n'
               'è‰¾è‰é—®ï¼šâ€œè’‚ç±³ï¼Œä½ æ€ä¹ˆèººç€ï¼Ÿâ€  \n'
               'â€œæˆ‘å’Œè›‡è¨ç±³æ‰“æ¶ï¼Œâ€è’‚ç±³æ‚²ä¼¤åœ°å›ç­”ã€‚  \n'
               'è‰¾è‰çœ‹åˆ°æœ‹å‹ä»¬æ‰“æ¶ï¼Œå¿ƒé‡Œå¾ˆéš¾è¿‡ã€‚å¥¹è¯´ï¼šâ€œæ‰“æ¶å¯ä¸å¥½ï¼Œæˆ‘ä»¬åº”è¯¥åšæœ‹å‹ï¼Œä¸€èµ·ç©ã€‚â€  \n'
               'è’‚ç±³åŒæ„äº†è‰¾è‰ï¼Œä»–ä»¬ä¸€èµ·å»æ‰¾è¨ç±³ã€‚å½“ä»–ä»¬æ‰¾åˆ°è¨ç±³æ—¶ï¼Œä»–ä»¬äº’ç›¸é“æ­‰ï¼Œé‡æ–°æˆä¸ºäº†å¥½æœ‹å‹ã€‚ä»é‚£å¤©èµ·ï¼Œä»–ä»¬éƒ½ä¸€èµ·ç©ï¼Œåœ¨ä¸›æ—é‡Œç©å¾—å¾ˆå¼€å¿ƒã€‚'}
    {'input': 'è¯æ±‡ï¼šæ»šï¼Œæ¯”è¨ï¼Œæ‰“å¼€\n'
              'æ‘˜è¦ï¼šè’‚å§†è¯•å›¾ä»ä¸€å®¶å¼€ç€çš„æ¯”è¨åº—æ‹¿ä¸€å—å¤§æ¯”è¨ï¼Œä½†å®ƒå¤ªå¤§äº†ï¼Œæ‰€ä»¥ä»–å†³å®šæŠŠå®ƒæ»šèµ°ã€‚ä¸€åªç‹—çœ‹åˆ°äº†æ¯”è¨ï¼Œè¿½ç€è’‚å§†ï¼Œåƒæ‰äº†æ¯”è¨ï¼Œç•™ä¸‹è’‚å§†æ„Ÿåˆ°ä¼¤å¿ƒã€‚',
     'instruction': 'æŒ‰ç…§ä¸‹é¢è¾“å…¥çš„çº¦æŸç”Ÿæˆæ•…äº‹',
     'output': 'ä¸€å¤©ï¼Œä¸€ä¸ªåå«è’‚å§†çš„ç”·å­©å»äº†æ¯”è¨åº—ã€‚ä»–ç‰¹åˆ«å–œæ¬¢æ¯”è¨ã€‚åœ¨æ¯”è¨åº—é‡Œï¼Œä»–çœ‹åˆ°æ¡Œå­ä¸Šæœ‰ä¸€ä¸ªå¤§æ¯”è¨ã€‚å®ƒçœ‹èµ·æ¥å¾ˆå¥½åƒï¼  \n'
               'è’‚å§†è¯´ï¼šâ€œå“‡ï¼Œæˆ‘æƒ³åƒé‚£å—æ¯”è¨ï¼â€ä»–è¯•å›¾æ‹¿èµ·æ¯”è¨ï¼Œä½†å®ƒå¤ªå¤§äº†ã€‚æ‰€ä»¥ï¼Œä»–å†³å®šæŠŠæ¯”è¨æ»šèµ°ã€‚ä»–æŠŠæ¯”è¨æ»šå‡ºäº†æ¯”è¨åº—ã€‚  \n'
               'å½“è’‚å§†æŠŠæ¯”è¨æ»šä¸‹è¡—çš„æ—¶å€™ï¼Œä¸€åªå¤§ç‹—çœ‹åˆ°äº†æ¯”è¨ã€‚é‚£åªç‹—å¾ˆé¥¿ã€‚ç‹—è¯´ï¼šâ€œæˆ‘ä¹Ÿæƒ³åƒé‚£å—æ¯”è¨ï¼â€ç‹—å¼€å§‹è¿½ç€è’‚å§†å’Œä»–çš„æ¯”è¨ã€‚  \n'
               'è’‚å§†è·‘å¾—å¾ˆå¿«ï¼Œä½†ç‹—è·‘å¾—æ›´å¿«ã€‚ç‹—è¿½ä¸Šäº†è’‚å§†å’Œä»–çš„æ¯”è¨ã€‚ç‹—åƒæ‰äº†æ•´å—æ¯”è¨ï¼Œè’‚å§†æ„Ÿåˆ°ä¼¤å¿ƒã€‚é‚£å¤©ä»–ä¸€å£æ¯”è¨éƒ½æ²¡åƒåˆ°ã€‚'}
    {'input': 'è¯æ±‡ï¼šé¼“æŒï¼Œæµ·æ´‹ï¼Œå±é™©\n'
              'ç‰¹å¾ï¼šå¯¹è¯\n'
              'æ‘˜è¦ï¼šè‰è‰å’Œè¨å§†æƒ³åœ¨æµ·æ´‹ä¸­æ¸¸æ³³ï¼Œä½†ä»–ä»¬çš„çˆ¶æ¯è¯´å¤ªå±é™©äº†ã€‚ä»–ä»¬åœ¨å²¸è¾¹å’Œæ–°æœ‹å‹ä¸€èµ·ç©çƒå’Œæ”¾é£ç­ï¼Œç©å¾—å¾ˆå¼€å¿ƒã€‚ä»–ä»¬åœ¨æ°´ä¸­çœ‹åˆ°ä¸€åªæµ·è±šï¼Œäº†è§£åˆ°æµ·æ´‹æ—¢ç¾å¦™åˆå±é™©ã€‚',
     'instruction': 'æŒ‰ç…§ä¸‹é¢è¾“å…¥çš„çº¦æŸç”Ÿæˆæ•…äº‹',
     'output': 'è‰è‰å’Œè¨å§†å’Œä»–ä»¬çš„çˆ¸çˆ¸å¦ˆå¦ˆåœ¨æµ·æ»©ä¸Šã€‚ä»–ä»¬å–œæ¬¢åœ¨æ²™å­é‡Œç©è€ï¼Œæ¬£èµæµ·æ´‹ã€‚æµ·æ´‹åˆå¤§åˆè“ï¼Œå‘å‡ºéš†éš†çš„å£°éŸ³ã€‚  \n'
               'â€œå¦ˆå¦ˆï¼Œæˆ‘ä»¬å¯ä»¥ä¸‹æ°´å—ï¼Ÿâ€è‰è‰é—®ã€‚  \n'
               'â€œä¸è¡Œï¼Œäº²çˆ±çš„ï¼Œä»Šå¤©æ°´å¤ªå±é™©äº†ã€‚æœ‰å¤§æµªå’Œå¼ºæµã€‚ä½ ä»¬å¯èƒ½ä¼šå—ä¼¤æˆ–è€…è¿·è·¯ï¼Œâ€å¦ˆå¦ˆè¯´ã€‚  \n'
               'â€œä½†æ˜¯æˆ‘æƒ³æ¸¸æ³³ï¼Œå¦ˆå¦ˆã€‚æˆ‘æ¸¸å¾—å¾ˆå¥½ã€‚ä½ æ•™è¿‡æˆ‘æ€ä¹ˆæ¸¸æ³³ï¼Œè®°å¾—å—ï¼Ÿâ€è¨å§†è¯´ã€‚  \n'
               'â€œæˆ‘çŸ¥é“ï¼Œäº²çˆ±çš„ï¼Œä½†åœ¨æµ·æ´‹é‡Œæ¸¸æ³³å’Œåœ¨æ¸¸æ³³æ± é‡Œæ¸¸æ³³æ˜¯ä¸åŒçš„ã€‚æµ·æ´‹å¯¹ä½ ä»¬è¿™ç§å°å­©æ¥è¯´ä¸å®‰å…¨ã€‚ä½ ä»¬å¿…é¡»å¬çˆ¸çˆ¸å¦ˆå¦ˆçš„è¯ï¼Œå¾…åœ¨å²¸è¾¹ï¼Œå¥½å—ï¼Ÿâ€çˆ¸çˆ¸è¯´ã€‚  \n'
               'è‰è‰å’Œè¨å§†æ„Ÿåˆ°éš¾è¿‡ã€‚ä»–ä»¬æƒ³åœ¨æ°´é‡Œç©å¾—å¼€å¿ƒã€‚ä»–ä»¬çœ‹åˆ°å…¶ä»–å°æœ‹å‹åœ¨ç©çƒå’Œæ”¾é£ç­ã€‚ä»–ä»¬å†³å®šåŠ å…¥ä»–ä»¬ï¼Œäº¤ä¸€äº›æ–°æœ‹å‹ã€‚  \n'
               'ä»–ä»¬ç©çƒå’Œæ”¾é£ç­ç©å¾—ç‰¹åˆ«å¼€å¿ƒã€‚ä»–ä»¬äº’ç›¸æ‰”çƒï¼Œè¿½ç€é£ç­è·‘ã€‚ä»–ä»¬æ¬¢ç¬‘ã€å–Šå«ã€æ¬¢å‘¼ã€‚ä»–ä»¬å¿˜è®°äº†æ°´ï¼Œäº«å—ç€é˜³å…‰å’Œå¾®é£ã€‚  \n'
               'ä¸ä¹…ï¼Œåˆ°äº†å›å®¶çš„æ—¶é—´ã€‚çˆ¸çˆ¸å¦ˆå¦ˆæ”¶æ‹¾å¥½ä¸œè¥¿ï¼Œå«è‰è‰å’Œè¨å§†ã€‚ä»–ä»¬å’Œæ–°æœ‹å‹é“åˆ«ï¼Œæ„Ÿè°¢ä»–ä»¬ä¸€èµ·ç©ã€‚  \n'
               'å½“ä»–ä»¬èµ°å‘è½¦æ—¶ï¼Œä»–ä»¬çœ‹åˆ°ç å¤´ä¸Šæœ‰ä¸€ç¾¤äººã€‚ä»–ä»¬åœ¨çœ‹æ°´é‡Œçš„ä¸œè¥¿ã€‚ä»–ä»¬å¬åˆ°äº†ä¸€äº›é¼“æŒå’Œæ¬¢å‘¼å£°ã€‚  \n'
               'â€œä»–ä»¬åœ¨çœ‹ä»€ä¹ˆï¼Œçˆ¸çˆ¸ï¼Ÿâ€è‰è‰é—®ã€‚  \n'
               'â€œæˆ‘ä»¬å»çœ‹çœ‹ï¼Œäº²çˆ±çš„ï¼Œâ€çˆ¸çˆ¸è¯´ã€‚  \n'
               'ä»–ä»¬èµ°åˆ°ç å¤´ï¼Œçœ‹åˆ°ä¸€æ¡å¤§é±¼ä»æ°´é‡Œè·³å‡ºæ¥ã€‚å®ƒæ˜¯ç°è‰²çš„ï¼Œé—ªé—ªå‘äº®ï¼Œé¼»å­è¿˜å¾ˆé•¿ã€‚å®ƒæ˜¯ä¸€åªæµ·è±šã€‚å®ƒåœ¨æ³¢æµªä¸­ç©è€å’Œè·³èˆã€‚å®ƒå‘å‡ºä¸€äº›æœ‰è¶£çš„å£°éŸ³ï¼Œæº…èµ·æ°´èŠ±ã€‚  \n'
               'â€œå“‡ï¼Œçœ‹çœ‹é‚£ä¸ªï¼Œè¨å§†ã€‚æ˜¯ä¸€åªæµ·è±šã€‚å¤ªé…·äº†ï¼Œâ€è‰è‰è¯´ã€‚  \n'
               'â€œå¤ªç¥å¥‡äº†ï¼Œè‰è‰ã€‚å®ƒèªæ˜åˆå‹å¥½ã€‚å®ƒä¸åƒæ°´é‚£æ ·å±é™©ã€‚çœŸä¸é”™ï¼Œâ€è¨å§†è¯´ã€‚  \n'
               'ä»–ä»¬çœ‹äº†ä¸€ä¼šå„¿æµ·è±šã€‚æ¯æ¬¡æµ·è±šè·³è·ƒã€æ—‹è½¬æˆ–æŒ¥æ‰‹æ—¶ï¼Œä»–ä»¬éƒ½é¼“æŒæ¬¢å‘¼ã€‚ä»–ä»¬å¾®ç¬‘ç€æŒ¥æ‰‹å›åº”ã€‚ä»–ä»¬æ„Ÿåˆ°å¿«ä¹å’Œå…´å¥‹ã€‚  \n'
               'ä»–ä»¬é‚£å¤©å­¦åˆ°äº†å¾ˆå¤šæ–°ä¸œè¥¿ã€‚ä»–ä»¬æ˜ç™½äº†æµ·æ´‹ä¸ä»…å±é™©ï¼Œè¿˜æœ‰å¾ˆå¤šç¾å¦™çš„åœ°æ–¹ã€‚ä»–ä»¬å­¦åˆ°åœ¨æµ·æ»©ä¸Šæœ‰å¾ˆå¤šä¸œè¥¿å¯ä»¥çœ‹ã€å¯ä»¥åšå’Œå¯ä»¥äº«å—ã€‚ä»–ä»¬å­¦åˆ°å¯ä»¥åœ¨ä¸ä¸‹æ°´çš„æƒ…å†µä¸‹ç©å¾—å¼€å¿ƒã€‚ä»–ä»¬å­¦åˆ°å¯ä»¥äº¤æ–°æœ‹å‹ï¼Œçœ‹åˆ°æ–°åŠ¨ç‰©ã€‚ä»–ä»¬å­¦åˆ°å¯ä»¥ä¸ºæµ·è±šé¼“æŒã€‚'}
    {'input': 'ç‰¹å¾ï¼šå¯¹è¯ï¼Œé“å¾·ä»·å€¼\n'
              'éšæœºå¥å­ï¼šä¸€å¤©ï¼Œç­å°¼çœ‹åˆ°åœ°ä¸Šæœ‰ä¸€æŠŠæ¢³å­ã€‚\n'
              'æ‘˜è¦ï¼šå…”å­ç­å°¼åœ¨æ„å¤–æ‹¿èµ°äº†ä¸€æŠŠå±äºå°å¥³å­©çš„æ¢³å­ï¼Œå¹¶åæ¥é‡åˆ°ä¸€åªæ­»é¸Ÿåï¼Œæ˜ç™½äº†è¯šå®å’Œå°Šé‡ç”Ÿå‘½çš„é‡è¦æ€§ã€‚',
     'instruction': 'æŒ‰ç…§ä¸‹é¢è¾“å…¥çš„çº¦æŸç”Ÿæˆæ•…äº‹',
     'output': 'ä»å‰ï¼Œæœ‰ä¸€åªå«ç­å°¼çš„å…”å­ã€‚ç­å°¼å–œæ¬¢æ•´å¤©è·³è·ƒå’Œç©è€ã€‚ä¸€å¤©ï¼Œç­å°¼çœ‹åˆ°åœ°ä¸Šæœ‰ä¸€æŠŠæ¢³å­ã€‚ä»–è§‰å¾—æŒºæœ‰æ„æ€çš„ï¼Œå†³å®šæ¡èµ·æ¥ã€‚  \n'
               'å½“ç­å°¼åœ¨æ¢³ç†è‡ªå·±çš„æ¯›å‘æ—¶ï¼Œä»–å¬åˆ°ä¸€ä¸ªå£°éŸ³è¯´ï¼šâ€œå˜¿ï¼Œå…”å­ï¼é‚£æŠŠæ¢³å­æ˜¯æˆ‘çš„ï¼â€è¿™æ˜¯ä¸€ä¸ªå°å¥³å­©ï¼Œå¥¹æ‰äº†æ¢³å­ã€‚ç­å°¼å› ä¸ºæ²¡æœ‰è¯¢é—®å°±æ‹¿èµ°äº†æ¢³å­è€Œæ„Ÿåˆ°å¾ˆä¸å¥½æ„æ€ï¼Œè¿…é€ŸæŠŠæ¢³å­è¿˜ç»™äº†å¥¹ã€‚  \n'
               'å°å¥³å­©å¾ˆé«˜å…´ï¼Œè°¢ç­å°¼çš„è¯šå®ã€‚å¥¹å‘Šè¯‰ä»–ï¼Œåœ¨æ‹¿ä¸œè¥¿ä¹‹å‰ä¸€å®šè¦å…ˆé—®æ˜¯å¾ˆé‡è¦çš„ã€‚ç­å°¼ä¸ºè‡ªå·±åšå¯¹äº†äº‹æƒ…è€Œæ„Ÿåˆ°è‡ªè±ªï¼Œé«˜é«˜å…´å…´åœ°è·³å¼€äº†ã€‚  \n'
               'å½“ä»–è·³æ¥è·³å»æ—¶ï¼Œç­å°¼çœ‹åˆ°åœ°ä¸Šæœ‰ä¸€åªæ­»é¸Ÿã€‚ä»–æƒ³èµ·äº†å°å¥³å­©çš„è¯ï¼ŒçŸ¥é“å°Šé‡ç”Ÿå‘½æ˜¯å¾ˆé‡è¦çš„ï¼Œå³ä½¿å®ƒä»¬å·²ç»ä¸å†æ´»ç€ã€‚ç­å°¼ä¸ºé‚£åªé¸Ÿé»˜å“€ï¼Œç»§ç»­ä»–çš„è·¯ç¨‹ï¼Œå¿ƒé‡Œæ„Ÿæ¿€è‡ªå·±å­¦åˆ°çš„æ•™è®­ã€‚'}


## å°ç»“
1. åŸºäº`TinyStories`çš„`Instruct`æ•°æ®è¿›è¡ŒæŒ‡ä»¤ç»„åˆå±‚é¢å‡è¡¡çš„é‡‡æ ·ï¼Œè·å¾—äº†15000æ¡åŸå§‹æ•°æ®
2. æ„é€ äº†ç¿»è¯‘å‡½æ•°ï¼Œå¼‚æ­¥ä½¿ç”¨å´æ©è¾¾è€å¸ˆçš„`translation-agent`å¯¹æ•°æ®è¿›è¡Œç¿»è¯‘
3. åŸºäºç¿»è¯‘åçš„æ•°æ®ï¼Œæ„é€ äº†ç»å…¸æ ¼å¼çš„`SFT`æ•°æ®é›†


