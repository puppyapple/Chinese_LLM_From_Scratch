{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从零手搓中文大模型｜🚀 Day09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "微软的`Tinystories`论文里，是直接在200w条`Instruction`数据上做的全量`pretrain`来验证小参数`LLM`的指令遵从效果的。\n",
    "\n",
    "为了挖掘`SLM`的潜力，我想看看在超小规模参数的情况下，少量（相比于`pretrain`）数据的`SFT`是否能起作用。\n",
    "\n",
    "（当然还有一个原因是要把`Instruction`数据全通过`GPT API`翻译一遍还是相当贵的😂）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全参数SFT训练实验🧪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上一期分享了一些`SFT`训练相关的知识点，里面提到了关于训练模式的选择。\n",
    "\n",
    "我的这个项目里，用于`SFT`训练的数据和之前预训练的数据分布是非常相似的，所以这里不打算将`SFT`数据用于`continue pretrain`，而是直接将`SFT`数据用于`finetuning`。\n",
    "\n",
    "由于`SFT`全量`finetuning`其实本质上和`pretrain`没有什么差别，只是在计算`loss`的时候对`prompt`部分做了一个`mask`，所以这里就不对训练参数配置做过多的介绍了。\n",
    "\n",
    "> 这里额外提一点，我在上构造的数据基础上做了一个增强的操作（用`GPT API`翻译还是太贵了😂）。\n",
    "> \n",
    "> 具体操作是：将上期用吴恩达老师的`translation-agent`翻译构造的数据里的指令部分里的多个约束抽取成了`key: value`，然后随机排列，输出还是故事本身不变，这样就得到了很多新的数据（从之前的1.3w条数据增加到了7.1w条）。\n",
    "> \n",
    "> 另外还有一个潜在的好处就是可以让模型知道指令内部的多个约束的顺序是不敏感的，只要输出符合所有指令的约束就可以。\n",
    "\n",
    "我简单地做了几组实验：\n",
    "\n",
    "🟣 `learning_rate = 1e-4, bf16-true`\n",
    "\n",
    "🔴 `learning_rate = 5e-4, bf16-true`\n",
    "\n",
    "🟢 `learning_rate = 5e-4, bf16-true`，但学习率下降比前两者速度更快\n",
    "\n",
    "🔵 `learning_rate = 5e-4, bf16-mixed`，学习率和上一个一样\n",
    "\n",
    "![image_v2](https://erxuanyi-1257355350.cos.ap-beijing.myqcloud.com/image_v2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 为了方便观察，图里的曲线都是经过平滑之后的。\n",
    "\n",
    "可以发现几个问题🤔：\n",
    "\n",
    "1. 学习率使用`pretrain`的1/5的时候（`1e-4`），收敛程度不如使用和`pretrain`时一样的`5e-4`。\n",
    "\n",
    "   和上一期里搜集的经验描述有些不一致（`SFT`阶段的`learning_rate`使用`pretrain`的1/10的建议）。\n",
    "   \n",
    "   我个人理解是因为我的`SFT`数据和`pretrain`数据非常相似，且指令相对简单/单一（只是在故事前面加了一些约束文本），所以即使用比较大的学习率也没有出现震荡发散的情况，反而很容易收敛。\n",
    "\n",
    "2. 学习率被设置得下降更快的这一组，收敛速度也更快一些，这个也容易理解：在后期，模型已经非常接近最优解了，这时候学习率下降得快，可以更精细地学习以逼近最优解。\n",
    "3. 使用`bf16-mixed`的这一组，收敛速度和前一个差不多，但是loss整体还要更低一些"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果测试\n",
    "#### 单一约束\n",
    "\n",
    "我随便构造了几个简单的测试用例，其中的指令都只包含单一的约束。\n",
    "\n",
    "结果如下👇："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litgpt import LLM\n",
    "from litgpt.prompts import Phi2\n",
    "\n",
    "prompt_style = Phi2()\n",
    "llm = LLM.load(\n",
    "    model=\"../../Experiments/Output/sft/microstories_v2/bf16_mixed_5e-4/step-001000\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从前，有一只叫汤姆的胖猫。汤姆有一个最好的朋友，一只叫杰瑞的小老鼠。他们喜欢一起玩耍和分享。汤姆和杰瑞是最好的朋友。  \n",
      "一天，汤姆和杰瑞在玩一个大红球。他们玩得可开心了。然后，汤姆看到地上有个开关。他想看看它有什么作用。于是，他按下了开关，发生了意想不到的事情。  \n",
      "汤姆和杰瑞开始慌张。他们不知道该怎么办。突然，一只叫杰瑞的小老鼠从开关里跑了出来。汤姆和杰瑞看到彼此的反应，开心极了。他们笑着拥抱在一起。从那天起，汤姆和杰瑞就一直是最好的朋友。  \n",
      "总结一下：一只胖猫汤姆和一只杰瑞一起玩开关，变成了一个有趣的发现。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "从前，有一个小男孩叫詹姆斯。他喜欢在草地上玩。一天，他在草地上看到一把铲子，决定捡起来。他开始挖土，挖了很久，突然看到有什么东西藏在土里。  \n",
      "詹姆斯非常好奇，于是开始用铲子挖。他挖呀挖，终于找到了什么东西。他不停地挖，直到看到一把大武器！  \n",
      "詹姆斯既惊讶又害怕，但他还是勇敢地把武器捡了起来。他把武器给妈妈看，妈妈非常为他骄傲。  \n",
      "“詹姆斯，你在草地上找到了什么啊？”妈妈问。  \n",
      "詹姆斯举起武器，说：“我不知道，但我很勇敢。”  \n",
      "妈妈微笑着说：“这武器看起来挺棘，詹姆斯。也许它是用来挖东西的啾。”  \n",
      "詹姆斯点头上挂着闪闪发光的铲子，\n",
      "----------------------------------------------------------------------------------------------------\n",
      "从前，有个小女孩叫莉莉。她喜欢在家里蹦蹦跳跳，玩得不亦乐乎。一天，她在厨房里发现了一个大圆形的水果。它是圆圆的，红红的。莉莉以为那是个球，但她不知道这是什么。  \n",
      "莉莉的妈妈看到她在玩水果，心里有些担心。她告诉莉莉那是苹果，不是球。莉莉虽然不太明白，但还是听妈妈的话，又回去玩她的玩具。  \n",
      "这次，莉莉的妈妈把水果切好了。她给莉莉一片红苹果。莉莉高兴得不得了，因为她喜欢苹果！她吃了苹果，感到很饱。从那天起，莉莉知道了这个水果是什么——是苹果！  \n",
      "小结：莉莉喜欢在厨房里的圆形水果，但她的妈给她切了一片，以后给她尝。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "从前，有一只小蚂蚁。蚂蚁小得可爱极了。它在花园里四处走动，寻找食物。突然，蚂蚁看到了一个大红苹果。它想咬一口苹果，但苹果太大了，蚂蚁够不着。  \n",
      "这时，蚂蚁看见了一只大棕蚂蚁。“请问，蚂蚁，您能帮我一下吗？”蚂蚁说。“当然，我可以帮你咬一口苹果。”棕色蚂蚁回答。  \n",
      "棕色蚂蚁用刀把苹果切成了两半。蚂蚁非常高兴，谢谢了朋友们。从那天起，蚂蚁们就开始互相分享食物了。  \n",
      "总结一下：蚂蚁们在花园里发现了一个大红苹果，但它太大，无法自己吃掉。棕色蚂蚂蚂蚁把苹果切开，发现里面有苹果，大家都很开心。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "从前，有一个小女孩叫莉莉。她喜欢在外面玩耍，仰望天空中美丽的蓬松白云。一天，她看到一朵大白云，看起来像一朵白云。她指着它说：“看，妈妈，一朵云！”  \n",
      "她的妈妈说：“那朵云真漂亮，莉莉。它是由天空中飘的一小堆云组成的。”  \n",
      "莉莉微笑着说：“我喜欢看云朵在天空中飘动。它们看起来像动物和植物。”  \n",
      "她的妈妈回答：“是的，它们看起来确实像动物和植物。也许它们都是云，但看起来像我们，不是很美。”  \n",
      "莉莉点头说：“是的，它们很美。我喜欢看云朵在天空中飘动。”  \n",
      "她的妈妈妈妈妈妈妈妈：“我也是，莉莉。天空中总是那么美丽。”\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_cases = [\n",
    "    {\n",
    "        \"instruction\": \"词汇：铲子，草地\\n\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"特点：转折\\n\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"摘要：一只小蚂蚁在花园里寻找吃的，最后找到了一个苹果。\\n\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"随机句子：天空中飘着几朵白云。\\n\",\n",
    "    },\n",
    "]\n",
    "prompts = [prompt_style.apply(prompt=case[\"instruction\"]) for case in test_cases]\n",
    "prompts.insert(0, \"汤姆和杰瑞是一对好朋友\")\n",
    "for prompt in prompts:\n",
    "    text = llm.generate(\n",
    "        prompt=prompt,\n",
    "        max_new_tokens=300,\n",
    "        temperature=0.2,\n",
    "        top_p=0.9,\n",
    "        top_k=30,\n",
    "    )\n",
    "    print(text)\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到对简单的约束的支持意外地还是不错的：\n",
    "\n",
    "**关键词**能完全命中，**转折**虽然很**生硬**，但是看得出来理解了要加入转折。\n",
    "\n",
    "根据**摘要**生成也比较准确，**随机句子**方面没有办法完全包含原句，但是大差不差（感觉完全包含还是有点难为这个尺寸的模型了）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 组合约束\n",
    "再来看看组合约束的效果👇："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从前，有一个聪明的女孩叫露西。她喜欢在草地上玩耍。每天，她都会在草地上跑、跳、穿梭。  \n",
      "一天，露西在草地上看到一把锋利的铲子。她捡起来开始玩。她像船一样在地上划过来。真是太好玩了！  \n",
      "露西的朋友汤姆来找她玩。他看到她在玩铲子，也想来试试。他们都假装在草地上划过来。他们笑着玩得特别开心。  \n",
      "突然，露西踩到了一个坎子，铲子飞了起来！汤姆和露西都很惊讶，他们不知道那把铲子怎么会到那里的。他们在草地上飞快地跑着，铲子帮助他们找到更多的故事来探索。  \n",
      "总结一下：露西在草地上发现了一把锹，她在草地上用它当作船，她和她的朋友汤姐姐姐在一起玩耍。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "从前有一只小蚂蚁，它是周围最小的蚂蚁。每天，这只小蚂蚁都在寻找食物。一天，它突然想到一个主意。它决定好好铺一块碗，里面放着一些食物，让其他蚂蚁也能吃。  \n",
      "小蚂蚁小心翼翼地把食物倒入碗中。然后，它开始四处张望。它看到了许多美味的苹果片，真是太甜了！它忍不住咬了一口苹果，这是它吃过的最好吃的苹果。  \n",
      "小蚂蚁非常高兴，开始带着碗回家。在路上，它注意到附近有几只蚂蚁。每只蚂蚁都有自己吃的食物。小蚂蚁真自豪华，心里满是这么多食物。  \n",
      "当小蚂蚁回到家时，它决定好好地把食物放在自己的碗里。这样，它就可以和其他蚂蚂蚁一起分享。现在，所有的蚂蚁都能吃到食物，大家都很开心。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "从前，有一只小蚂蚁住在花园里。蚂蚁喜欢花园里的草地。一天，蚂蚁在花园里散步时，看见了一棵大树。树上结满了苹果。蚂蚁非常高兴，爬上了树。  \n",
      "当蚂蚁到达树顶时，它看到一个苹果。那是一个鲜艳的苹果，看起来真好吃。但就在他准备咬一口时，他听到了一声响亮的声音。那是树枝上的一只声音。树枝枝枝折断了，蚂蚁掉到了地上。  \n",
      "蚂蚁很害怕，但它没事。它爬回了家，吃了其他食物。结束。\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_cases = [\n",
    "    {\n",
    "        \"instruction\": \"词汇：铲子，草地\\n特点：转折\\n\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"词汇：铲子，草地\\n摘要：一只小蚂蚁在花园里寻找吃的，最后找到了一个苹果。\\n\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"词汇：铲子，草地\\n随机句子：天空中飘着几朵白云。\\n摘要：一只小蚂蚁在花园里寻找吃的，最后找到了一个苹果。\\n\",\n",
    "    },\n",
    "]\n",
    "prompts = [prompt_style.apply(prompt=case[\"instruction\"]) for case in test_cases]\n",
    "for prompt in prompts:\n",
    "    text = llm.generate(\n",
    "        prompt=prompt,\n",
    "        max_new_tokens=300,\n",
    "        temperature=0.9,\n",
    "        top_p=1,\n",
    "        top_k=30,\n",
    "    )\n",
    "    print(text)\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "混合约束的难度明显上升了，虽然看得出模型在努力地理解指令，但是结果并不理想。\n",
    "\n",
    "一方面可能我的`base`模型训练得可能还不够充分，另一方面`SFT`数据量少了。\n",
    "\n",
    "对于`SFT`之后模型生成的连贯性和逻辑性出现明显下降的问题，简单地检索了一下，一个可能的优化方法是在`SFT`数据里加入一些`pretrain`里的数据，这种做法称为`Replay`。\n",
    "\n",
    "时间有限还没来得及尝试，等后面有时间了可以试试，在之后的更新里同步分享结果给大家吧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LORA微调⌛\n",
    "\n",
    "我也尝试了在`SFT`数据上用`LORA`微调，发现效果并不好，loss下降得很慢，且远高于`SFT`全量微调的loss。\n",
    "\n",
    "![image4](https://erxuanyi-1257355350.cos.ap-beijing.myqcloud.com/image4.png)\n",
    "\n",
    "如上图，黄色🟡的是全量微调的loss，红色🔴的是`LORA`微调的loss，这里虽然只有两条，但实际上我尝试了不少`learning rate`和其他参数的组合，但结果都差不多。\n",
    "\n",
    "我猜测是因为模型太小了，用`Lora`微调时候使用较小的`r`和`alpha`，可训练参数量就更小，所以效果不好。\n",
    "\n",
    "于是我试了下将`Lora`的`r`和`alpha`调大（🟠从`8_16`调到`256_512`），发现效果好了不少，loss下降得更快了，但收敛速度还是要**远远慢于**全量微调。\n",
    "\n",
    "这时候的可训练参数量级已经接近`22M`，正好是模型自身的一半了，效果变好也是理所当然的，但这样显然已经失去了`LORA`微调的意义。\n",
    "\n",
    "> 关于`Lora`的正常使用，后面等有机会训练一个更大的`base model`的时候再尝试吧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "1. 分享了`SFT`全量微调的一些实验结果\n",
    "2. 测试了一下`SFT`全量微调之后的指令遵循效果\n",
    "3. 分享了用`LORA`微调的一些实验结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigmodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
